{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8aa50d-64d9-4980-bd0b-72ca799ed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing self-consistency check on 256861 records...\n",
      "\n",
      "Consistency Check Results (Threshold: 0.1 deg):\n",
      "Total Records: 256861\n",
      "Inconsistent Records: 236821\n",
      "Inconsistency Rate: 92.20%\n",
      "\n",
      "Sample of inconsistent records (Original vs Calculated):\n",
      "                  date  group_id  hg_lon  calc_hg_lon  hcc_lon  calc_hcc_lon\n",
      "0  1874-05-09 11:55:40      8600   -30.7   -30.548356    171.6    171.805220\n",
      "1  1874-05-09 11:55:40      8700   -47.2   -46.983239    155.1    155.370337\n",
      "2  1874-05-09 11:55:40      8800    46.8    46.564835    249.1    248.918411\n",
      "3  1874-05-10 00:00:00      8600   -16.7   -16.602151    172.2    179.099845\n",
      "4  1874-05-10 00:00:00      8500    59.7    59.449574    248.5    255.151570\n",
      "\n",
      "Validation complete. Proceed to Cell 2 for final data generation.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Sunspot Group Coordinate Self-consistency Check\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sunpy.coordinates import frames\n",
    "from sunpy.coordinates.sun import angular_radius as solar_semidiameter_angular_size\n",
    "import warnings\n",
    "from erfa import ErfaWarning\n",
    "import os\n",
    "\n",
    "# Ignore specific types of warnings\n",
    "warnings.filterwarnings('ignore', category=ErfaWarning)\n",
    "\n",
    "# Define data directory\n",
    "data_dir = '../../data/interm'\n",
    "\n",
    "# Read filtered source data\n",
    "input_file = os.path.join(data_dir, 'sg_gsn_ar_source_filtered.csv')\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"Performing self-consistency check on {len(df)} records...\")\n",
    "\n",
    "# 1. Vectorized Calculation of Coordinates from dist_c and pa\n",
    "df['date_dt'] = pd.to_datetime(df['date'], format='mixed')\n",
    "times = Time(df['date_dt'].tolist())\n",
    "angular_radii = solar_semidiameter_angular_size(times).to(u.arcsec)\n",
    "\n",
    "radius = df['dist_c'].values\n",
    "pa_rad = np.radians(df['pa'].values)\n",
    "x_arcsec = -1 * radius * angular_radii.value * np.sin(pa_rad)\n",
    "y_arcsec = radius * angular_radii.value * np.cos(pa_rad)\n",
    "\n",
    "hpc_coords = SkyCoord(x_arcsec * u.arcsec, y_arcsec * u.arcsec, \n",
    "                      frame=frames.Helioprojective, \n",
    "                      observer=\"earth\", \n",
    "                      obstime=times)\n",
    "\n",
    "# Transform to HGS and HGC\n",
    "hgs_coords = hpc_coords.transform_to(frames.HeliographicStonyhurst)\n",
    "hgc_coords = hpc_coords.transform_to(frames.HeliographicCarrington)\n",
    "\n",
    "# 2. Compare with original columns\n",
    "# Original columns: hg_lon, hg_lat, hcc_lon\n",
    "# Threshold for inconsistency (degrees)\n",
    "threshold = 0.1\n",
    "\n",
    "lon_diff = np.abs(df['hg_lon'] - hgs_coords.lon.deg)\n",
    "lat_diff = np.abs(df['hg_lat'] - hgs_coords.lat.deg)\n",
    "hcc_diff = np.abs(df['hcc_lon'] - hgc_coords.lon.deg)\n",
    "\n",
    "# Handle 360 degree wrap-around for longitudes\n",
    "lon_diff = np.minimum(lon_diff, 360 - lon_diff)\n",
    "hcc_diff = np.minimum(hcc_diff, 360 - hcc_diff)\n",
    "\n",
    "inconsistent_mask = (lon_diff > threshold) | (lat_diff > threshold) | (hcc_diff > threshold)\n",
    "inconsistent_count = inconsistent_mask.sum()\n",
    "total_count = len(df)\n",
    "\n",
    "print(f\"\\nConsistency Check Results (Threshold: {threshold} deg):\")\n",
    "print(f\"Total Records: {total_count}\")\n",
    "print(f\"Inconsistent Records: {inconsistent_count}\")\n",
    "print(f\"Inconsistency Rate: {inconsistent_count/total_count:.2%}\")\n",
    "\n",
    "if inconsistent_count > 0:\n",
    "    print(\"\\nSample of inconsistent records (Original vs Calculated):\")\n",
    "    check_df = df[inconsistent_mask].copy()\n",
    "    check_df['calc_hg_lon'] = hgs_coords.lon.deg[inconsistent_mask]\n",
    "    check_df['calc_hg_lat'] = hgs_coords.lat.deg[inconsistent_mask]\n",
    "    check_df['calc_hcc_lon'] = hgc_coords.lon.deg[inconsistent_mask]\n",
    "    print(check_df[['date', 'group_id', 'hg_lon', 'calc_hg_lon', 'hcc_lon', 'calc_hcc_lon']].head())\n",
    "\n",
    "print(\"\\nValidation complete. Proceed to Cell 2 for final data generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d35602-3065-4d4a-897f-131e335bbc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating high-precision base data for 256861 records...\n",
      "Transforming to HGS, HGC, and HME...\n",
      "Task completed. Saved to ../../data/interm/sg_base_data.csv\n",
      "                  date  group_id     hg_lon     hg_lat     hcc_lon     hme_lon\n",
      "0  1874-05-09 11:55:40      8600 -30.548356   7.263551  171.805220  200.788266\n",
      "1  1874-05-09 11:55:40      8700 -46.983239  -7.091279  155.370337  183.466083\n",
      "2  1874-05-09 11:55:40      8800  46.564835  20.340915  248.918411  279.457868\n",
      "3  1874-05-10 00:00:00      8600 -16.602151   7.078445  179.099845  215.385935\n",
      "4  1874-05-10 00:00:00      8500  59.449574  -5.255530  255.151570  289.754839\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Final Base Data Generation (High Precision)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord, HeliocentricMeanEcliptic\n",
    "from sunpy.coordinates import frames\n",
    "from sunpy.coordinates.sun import angular_radius as solar_semidiameter_angular_size\n",
    "import warnings\n",
    "from erfa import ErfaWarning\n",
    "import os\n",
    "\n",
    "# Ignore specific types of warnings\n",
    "warnings.filterwarnings('ignore', category=ErfaWarning)\n",
    "\n",
    "# Define data directory\n",
    "data_dir = '../../data/interm'\n",
    "\n",
    "# Read filtered source data\n",
    "input_file = os.path.join(data_dir, 'sg_gsn_ar_source_filtered.csv')\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "print(f\"Generating high-precision base data for {len(df)} records...\")\n",
    "\n",
    "# 1. Vectorized Calculation\n",
    "df['date_dt'] = pd.to_datetime(df['date'], format='mixed')\n",
    "times = Time(df['date_dt'].tolist())\n",
    "angular_radii = solar_semidiameter_angular_size(times).to(u.arcsec)\n",
    "\n",
    "radius = df['dist_c'].values\n",
    "pa_rad = np.radians(df['pa'].values)\n",
    "x_arcsec = -1 * radius * angular_radii.value * np.sin(pa_rad)\n",
    "y_arcsec = radius * angular_radii.value * np.cos(pa_rad)\n",
    "\n",
    "hpc_coords = SkyCoord(x_arcsec * u.arcsec, y_arcsec * u.arcsec, \n",
    "                      frame=frames.Helioprojective, \n",
    "                      observer=\"earth\", \n",
    "                      obstime=times)\n",
    "\n",
    "# 2. Transform to all required frames\n",
    "print(\"Transforming to HGS, HGC, and HME...\")\n",
    "hgs_coords = hpc_coords.transform_to(frames.HeliographicStonyhurst)\n",
    "hgc_coords = hpc_coords.transform_to(frames.HeliographicCarrington)\n",
    "hme_coords = hgs_coords.transform_to(HeliocentricMeanEcliptic)\n",
    "\n",
    "# 3. Update DataFrame with calculated values\n",
    "# We replace original coordinates with calculated ones for consistency across the project\n",
    "df['hg_lon'] = hgs_coords.lon.deg\n",
    "df['hg_lat'] = hgs_coords.lat.deg\n",
    "df['hcc_lon'] = hgc_coords.lon.deg\n",
    "df['hcc_lon_calc'] = hgc_coords.lon.deg # Keep for backward compatibility\n",
    "df['hme_lon'] = hme_coords.lon.deg\n",
    "df['hme_lat'] = hme_coords.lat.deg\n",
    "\n",
    "# Drop temporary column\n",
    "df.drop(columns=['date_dt'], inplace=True)\n",
    "\n",
    "# 4. Save to base data file\n",
    "output_file = os.path.join(data_dir, 'sg_base_data.csv')\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f'Task completed. Saved to {output_file}')\n",
    "print(df[['date', 'group_id', 'hg_lon', 'hg_lat', 'hcc_lon', 'hme_lon']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1412d363-6b8c-4590-a54b-53d6c9436eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
