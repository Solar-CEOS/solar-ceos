{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c2a467",
   "metadata": {},
   "source": [
    "# Merge Planet and Satellite Ecliptic Coordinates with SSN\n",
    "\n",
    "This notebook merges the ecliptic longitude and latitude data for planets and satellites with the daily Sunspot Number (SSN) data.\n",
    "The output is a single Parquet file containing:\n",
    "- Date\n",
    "- SSN\n",
    "- Ecliptic Longitude and Latitude for all processed planets and satellites.\n",
    "\n",
    "Output file: `../../data/ready/planets_satellites_lonlat.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ab415e-e377-4a13-8cef-d6ddac55889e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: ../../data/00_raw/helio_ecl_sph_00h/planets_dwarfs_daily_1849\n",
      "Processing folder: ../../data/00_raw/helio_ecl_sph_00h/satellites_daily_1849\n",
      "Processing completed. Merged data has 73780 rows and 624 columns.\n",
      "Saved to: ../../data/ready/planets_satellites_lonlat.parquet\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Custom date parsing function to handle \"A.D. YYYY-MMM-DD HH:MM:SS.SSSS\" format\n",
    "def parse_special_date(date_str):\n",
    "    # Remove \"A.D. \" prefix\n",
    "    if isinstance(date_str, str) and \"A.D. \" in date_str:\n",
    "        date_str = date_str.replace(\"A.D. \", \"\")\n",
    "    # Parse the remaining part\n",
    "    try:\n",
    "        return pd.to_datetime(date_str, format=\"%Y-%b-%d %H:%M:%S.%f\")\n",
    "    except:\n",
    "        try:\n",
    "            return pd.to_datetime(date_str)\n",
    "        except:\n",
    "            # print(f\"Unable to parse date: {date_str}\")\n",
    "            return pd.NaT\n",
    "            \n",
    "# Read Sunspot Number (SSN) data\n",
    "ssn_path = '../../data/ready/ssn_daily_1849_2025.csv'\n",
    "df_ssn = pd.read_csv(ssn_path)\n",
    "\n",
    "# Convert date column to datetime format\n",
    "df_ssn['date'] = pd.to_datetime(df_ssn['date'])\n",
    "\n",
    "# Define folders to traverse (Ecliptic Longitude and Latitude)\n",
    "folder_paths = [\n",
    "    '../../data/00_raw/helio_ecl_sph_00h/planets_dwarfs_daily_1849',\n",
    "    '../../data/00_raw/helio_ecl_sph_00h/satellites_daily_1849'\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store merged data\n",
    "merged_df = None\n",
    "\n",
    "# Traverse all folders\n",
    "for folder_path in folder_paths:\n",
    "    print(f\"Processing folder: {folder_path}\")\n",
    "    \n",
    "    # Get all csv files in the folder\n",
    "    all_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "    \n",
    "    # Traverse all csv files in the folder\n",
    "    for file in all_files:\n",
    "        # print(f\"Processing file: {file}\")\n",
    "        # Read file\n",
    "        df_temp = pd.read_csv(file)\n",
    "        \n",
    "        # Convert date column to datetime format\n",
    "        if 'date' in df_temp.columns:\n",
    "            df_temp['date'] = df_temp['date'].apply(parse_special_date)\n",
    "        \n",
    "        # Remove columns with suffix \"_r\" (distance)\n",
    "        columns_to_keep = ['date'] + [col for col in df_temp.columns if col != 'date' and not col.endswith('_r')]\n",
    "        df_temp = df_temp[columns_to_keep]\n",
    "        \n",
    "        # If it's the first file, set it as the base DataFrame\n",
    "        if merged_df is None:\n",
    "            merged_df = df_temp\n",
    "        else:\n",
    "            # Otherwise, merge by date, keeping all columns\n",
    "            merged_df = pd.merge(merged_df, df_temp, on='date', how='outer')\n",
    "\n",
    "# Ensure merged_df is not empty\n",
    "if merged_df is None:\n",
    "    print(\"No files found or all files are empty\")\n",
    "else:\n",
    "    # Ensure date column is the first column\n",
    "    cols = merged_df.columns.tolist()\n",
    "    if 'date' in cols:\n",
    "        cols.remove('date')\n",
    "        cols = ['date'] + cols\n",
    "        merged_df = merged_df[cols]\n",
    "\n",
    "    # Merge SSN data (left merge based on date)\n",
    "    result_df = pd.merge(merged_df, df_ssn[['date', 'ssn']], on='date', how='left')\n",
    "\n",
    "    # Adjust column order: date first, ssn second\n",
    "    cols = result_df.columns.tolist()\n",
    "    if 'date' in cols:\n",
    "        cols.remove('date')\n",
    "    if 'ssn' in cols:\n",
    "        cols.remove('ssn')\n",
    "        result_df = result_df[['date', 'ssn'] + cols]\n",
    "    else:\n",
    "        print(\"Warning: ssn column not found after merge\")\n",
    "        result_df = result_df[['date'] + cols]\n",
    "\n",
    "    # Standardize date format to YYYY-MM-DD\n",
    "    result_df['date'] = pd.to_datetime(result_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Save result as Parquet in the final directory\n",
    "    output_path = '../../data/ready/planets_satellites_lonlat.parquet'\n",
    "    result_df.to_parquet(output_path, index=False)\n",
    "\n",
    "    print(f\"Processing completed. Merged data has {len(result_df)} rows and {len(result_df.columns)} columns.\")\n",
    "    print(f\"Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08274b-04d7-4a5a-9ba1-bfaf67fc13fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
