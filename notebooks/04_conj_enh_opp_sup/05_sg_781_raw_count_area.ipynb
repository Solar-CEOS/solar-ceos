{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73437b55-5cfa-4431-b18d-354045e7d56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Step: Exporting Raw Statistics (Count, Total Area, Avg Area)\n",
      "============================================================\n",
      "Processing Stage: All ...\n",
      "  - Bodies found: 781 | Total Records: 256824\n",
      "Processing Stage: Daily ...\n",
      "  - Bodies found: 781 | Total Records: 8301\n",
      "Processing Stage: Dissipation ...\n",
      "  - Bodies found: 781 | Total Records: 27870\n",
      "Processing Stage: Duration ...\n",
      "  - Bodies found: 781 | Total Records: 75678\n",
      "Processing Stage: Onset ...\n",
      "  - Bodies found: 781 | Total Records: 33278\n",
      "------------------------------------------------------------\n",
      "Calculation finished. Generating Excel file...\n",
      "[Success] File saved to: ../../results/04_conj_enh_opp_sup/sg\\sg_781_raw_count_area.csv\n",
      "Total Execution Time: 7.1 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Configuration\n",
    "# =============================================================================\n",
    "\n",
    "# Define Input/Output Directories\n",
    "# Based on the path structure from the original script\n",
    "BASE_OUTPUT_DIR = '../../results/04_conj_enh_opp_sup/sg'\n",
    "CACHE_DIR = os.path.join(BASE_OUTPUT_DIR, 'cache_data')\n",
    "\n",
    "# Output File Path\n",
    "OUTPUT_EXCEL_FILE = os.path.join(BASE_OUTPUT_DIR, 'sg_781_raw_count_area.csv')\n",
    "\n",
    "# Analysis Parameters\n",
    "# Windows in degrees (1 to 5)\n",
    "THRESHOLDS = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Filter warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Worker Function\n",
    "# =============================================================================\n",
    "\n",
    "def worker_algo3_excel_export(args):\n",
    "    \"\"\"\n",
    "    Core logic to calculate raw statistics for a single body.\n",
    "    \n",
    "    Args:\n",
    "        args (tuple): Contains (body_name, body_lons, sun_lons, sun_areas, thresholds)\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing statistics for each window/type.\n",
    "    \"\"\"\n",
    "    body_name, body_lons, sun_lons, sun_areas, thresholds = args\n",
    "    results = []\n",
    "    \n",
    "    # Pre-calculate integers for potential optimization (though not strictly needed for raw count)\n",
    "    # n_recs = len(sun_lons)\n",
    "    \n",
    "    for w in thresholds:\n",
    "        for etype in ['Opposition', 'Conjunction']:\n",
    "            \n",
    "            # --- A. Event Detection ---\n",
    "            if etype == 'Conjunction':\n",
    "                # Calculate difference for Conjunction (0 deg target)\n",
    "                d = np.abs(sun_lons - body_lons)\n",
    "                d = np.where(d > 180, 360 - d, d)\n",
    "                is_event = (d <= w)\n",
    "            else: \n",
    "                # Calculate difference for Opposition (180 deg target)\n",
    "                d = np.abs(np.abs(sun_lons - body_lons) - 180)\n",
    "                is_event = (d <= w)\n",
    "            \n",
    "            # --- B. Calculate Statistics ---\n",
    "            # 1. Raw Count (Frequency)\n",
    "            k_obs = np.sum(is_event)\n",
    "            \n",
    "            # 2. Area Statistics\n",
    "            if k_obs > 0:\n",
    "                # Extract area values for the specific event days\n",
    "                event_areas = sun_areas[is_event]\n",
    "                \n",
    "                # Calculate Total Area and Average Area\n",
    "                total_area = np.sum(event_areas)\n",
    "                avg_area = np.mean(event_areas)\n",
    "            else:\n",
    "                total_area = 0.0\n",
    "                avg_area = 0.0\n",
    "            \n",
    "            # --- C. Store Results ---\n",
    "            results.append({\n",
    "                'Body': body_name,\n",
    "                'Window': w,\n",
    "                'Type': etype,\n",
    "                'Raw_Count': int(k_obs),\n",
    "                'Total_Area': round(total_area, 2),\n",
    "                'Avg_Area': round(avg_area, 2)\n",
    "            })\n",
    "            \n",
    "    return results\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Main Execution Function\n",
    "# =============================================================================\n",
    "\n",
    "def run_extraction_to_excel():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Step: Exporting Raw Statistics (Count, Total Area, Avg Area)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Check if cache directory exists\n",
    "    if not os.path.exists(CACHE_DIR):\n",
    "        print(f\"[Error] Cache directory not found: {CACHE_DIR}\")\n",
    "        print(\"Please run Step 1 of the main script first to generate cache files.\")\n",
    "        return\n",
    "\n",
    "    # Get list of parquet files\n",
    "    files = [f for f in os.listdir(CACHE_DIR) if f.startswith('ready_') and f.endswith('.parquet')]\n",
    "    \n",
    "    if not files:\n",
    "        print(\"[Error] No 'ready_*.parquet' files found in cache.\")\n",
    "        return\n",
    "\n",
    "    all_results = []\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    for f in files:\n",
    "        # Extract stage name from filename (e.g., 'ready_Daily.parquet' -> 'Daily')\n",
    "        stage_name = f.replace('ready_', '').replace('.parquet', '')\n",
    "        print(f\"Processing Stage: {stage_name} ...\")\n",
    "        \n",
    "        # Load Data\n",
    "        file_path = os.path.join(CACHE_DIR, f)\n",
    "        try:\n",
    "            df = pd.read_parquet(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"  [Error] Failed to read {f}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Identify columns\n",
    "        # Meta columns to exclude\n",
    "        meta_cols = {'date', 'hme_lon', 'area', 'ephem_idx_daily', 'Group', 'lat_lon', 'hg_lon', 'hgc_lon', 'lon', 'lat'}\n",
    "        # Body columns end with '_lon'\n",
    "        body_cols = [c for c in df.columns if c not in meta_cols and c.endswith('_lon')]\n",
    "        \n",
    "        print(f\"  - Bodies found: {len(body_cols)} | Total Records: {len(df)}\")\n",
    "        \n",
    "        # Prepare numpy arrays (float32 for memory efficiency)\n",
    "        sun_lons = df['hme_lon'].values.astype(np.float32)\n",
    "        sun_areas = df['area'].values.astype(np.float32)\n",
    "        \n",
    "        # Iterate through each body\n",
    "        # Using a simple loop (Single-Core) to avoid multiprocessing overhead for this export task\n",
    "        for col in body_cols:\n",
    "            body_data = df[col].values.astype(np.float32)\n",
    "            \n",
    "            clean_body_id = col.replace('_lon', '')\n",
    "            # Prepare arguments\n",
    "            args = (clean_body_id, body_data, sun_lons, sun_areas, THRESHOLDS)\n",
    "            # Run worker\n",
    "            body_stats = worker_algo3_excel_export(args)\n",
    "            \n",
    "            # Append Stage info to results\n",
    "            for stat in body_stats:\n",
    "                stat['Stage'] = stage_name\n",
    "                all_results.append(stat)\n",
    "                \n",
    "    print(\"-\" * 60)\n",
    "    print(\"Calculation finished. Generating Excel file...\")\n",
    "    \n",
    "    if all_results:\n",
    "        # Create DataFrame\n",
    "        df_final = pd.DataFrame(all_results)\n",
    "        \n",
    "        # Reorder columns for better readability\n",
    "        cols_order = ['Stage', 'Body', 'Window', 'Type', 'Raw_Count', 'Total_Area', 'Avg_Area']\n",
    "        # Ensure only existing columns are selected\n",
    "        cols_order = [c for c in cols_order if c in df_final.columns]\n",
    "        df_final = df_final[cols_order]\n",
    "        \n",
    "        # 保存\n",
    "        try:\n",
    "            df_final.to_csv(OUTPUT_EXCEL_FILE, index=False)\n",
    "            print(f\"[Success] File saved to: {OUTPUT_EXCEL_FILE}\")\n",
    "            print(f\"Total Execution Time: {time.time() - total_start_time:.1f} seconds\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Failed to save file: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"[Warning] No results were generated. Please check your data.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run_extraction_to_excel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14dca5-54d1-4371-ad89-99d2a1b55190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312sunspot)",
   "language": "python",
   "name": "py312_sunspot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
