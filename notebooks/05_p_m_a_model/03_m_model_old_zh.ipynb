{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad40d410-0529-4e83-94a0-f4ea594c1e45",
   "metadata": {},
   "source": [
    "# èƒ½é‡åŒ…ç»œæµ‹è¯•è¡Œæ˜Ÿæ˜¯å¦è°ƒåˆ¶\n",
    "\n",
    "ä½¿ç”¨â€œèƒ½é‡åŒ…ç»œæ¨¡å‹â€ä½œä¸ºç­›é€‰å™¨ï¼Œæ¥ç³»ç»Ÿæ€§åœ°æ£€éªŒå“ªäº›åŸºç¡€é¢‘ç‡ï¼ˆæ®‹å·®ä¸­çš„ä¿¡å·ï¼‰çš„èƒ½é‡ï¼Œæ˜¯çœŸçš„å—åˆ°äº†11å¹´è¡Œæ˜Ÿå‘¨æœŸï¼ˆæ‹ŸåˆSSNï¼‰çš„è°ƒåˆ¶ã€‚è¿™ä¸ªæ–¹æ³•ï¼ˆé«˜é¢‘ä¿¡å·çš„èƒ½é‡åŒ…ç»œ vs ä½é¢‘é©±åŠ¨åŠ›ï¼‰åœ¨ç‰©ç†ä¸Šæ¯”LGBMçš„â€œå…¨é¢‘ç‡æ¢³â€ç‰¹å¾å·¥ç¨‹æ›´å…·å¯è§£é‡Šæ€§ã€‚æˆ‘ä»¬å°†ä¸å†å±€é™äº20-35å¤©ï¼Œè€Œæ˜¯éå†æ‰€æœ‰ç›¸å…³çš„ç‰©ç†é¢‘å¸¦ï¼ˆè‡ªè½¬ã€Riegerã€å¹´åº¦ã€QBOï¼‰ï¼Œå¹¶é‡åŒ–å®ƒä»¬å„è‡ªä¸11å¹´å‘¨æœŸçš„â€œè°ƒåˆ¶å…³ç³»â€ã€‚ç­›é€‰è°ƒåˆ¶é¢‘ç‡çš„å®Œæ•´ä»£ç ä»¥ä¸‹æ˜¯å®Œæ•´çš„Pythonè„šæœ¬ã€‚å®ƒä¼šï¼šå®šä¹‰ä¸€ç³»åˆ—ä½ æ„Ÿå…´è¶£çš„ç‰©ç†é¢‘å¸¦ï¼ˆå¤©ï¼‰ã€‚å¾ªç¯éå†4ä¸ªæ¨¡å‹ï¼ˆM8+2, M0+3...ï¼‰ã€‚å¯¹äºæ¯ä¸ªæ¨¡å‹ï¼Œå†å¾ªç¯éå†æ¯ä¸ªé¢‘å¸¦ã€‚æ ¸å¿ƒæ­¥éª¤ï¼šæå–è¯¥é¢‘å¸¦çš„èƒ½é‡åŒ…ç»œï¼Œå¹¶ï¼ˆç”¨ä¸€ä¸ªç®€å•çš„LGBMï¼‰æ‹Ÿåˆ $Y_{åŒ…ç»œ} = f(X_{è¡Œæ˜Ÿæ‹Ÿåˆ})$ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè®¡ç®—RÂ²ã€‚æœ€åæ±‡æ€»ä¸€å¼ è¡¨ï¼Œæ˜¾ç¤ºæ¯ä¸ªé¢‘å¸¦åœ¨4ä¸ªæ¨¡å‹ä¸Šçš„å¹³å‡RÂ²ï¼Œå‘Šè¯‰æ‚¨å“ªäº›é¢‘ç‡â€œå€¼å¾—â€è¢«è°ƒåˆ¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a4832d-1230-4b22-a1e7-5afbf28cb181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM å¯¼å…¥æˆåŠŸã€‚\n",
      "Scipy å¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: 1.15.2)ã€‚\n",
      "åŠ è½½æºæ•°æ®: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\n",
      "\n",
      "=== å¼€å§‹ç­›é€‰â€œèƒ½é‡åŒ…ç»œè°ƒåˆ¶â€çš„ç‰©ç†é¢‘å¸¦ ===\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+2 (è®­ç»ƒæˆªè‡³: 1996-08-01)\n",
      "==================================================\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Wide (20-40 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.679758\n",
      "  > Rotation_Wide æ£€éªŒ RÂ²: 0.3943\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Core (25-30 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 20.046650\n",
      "  > Rotation_Core æ£€éªŒ RÂ²: 0.2925\n",
      "  æµ‹è¯•é¢‘å¸¦: Rieger (140-170 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 8.188442\n",
      "  > Rieger æ£€éªŒ RÂ²: -0.2387\n",
      "  æµ‹è¯•é¢‘å¸¦: Annual (350-380 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 4.835737\n",
      "  > Annual æ£€éªŒ RÂ²: -0.6341\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_1.5_3.0y (547.875-1095.75 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 9.114447\n",
      "  > QBO_1.5_3.0y æ£€éªŒ RÂ²: 0.4471\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_2.2y (730.5-876.6 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 5.998310\n",
      "  > QBO_2.2y æ£€éªŒ RÂ²: -0.3194\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+3 (è®­ç»ƒæˆªè‡³: 1986-08-01)\n",
      "==================================================\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Wide (20-40 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.561354\n",
      "  > Rotation_Wide æ£€éªŒ RÂ²: 0.3229\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Core (25-30 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 19.796950\n",
      "  > Rotation_Core æ£€éªŒ RÂ²: 0.3428\n",
      "  æµ‹è¯•é¢‘å¸¦: Rieger (140-170 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 8.107376\n",
      "  > Rieger æ£€éªŒ RÂ²: -0.1263\n",
      "  æµ‹è¯•é¢‘å¸¦: Annual (350-380 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 5.011983\n",
      "  > Annual æ£€éªŒ RÂ²: -1.2428\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_1.5_3.0y (547.875-1095.75 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 8.969142\n",
      "  > QBO_1.5_3.0y æ£€éªŒ RÂ²: 0.2012\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_2.2y (730.5-876.6 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50251, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 5.819495\n",
      "  > QBO_2.2y æ£€éªŒ RÂ²: -0.1298\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+3 (è®­ç»ƒæˆªè‡³: 1986-09-01)\n",
      "==================================================\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Wide (20-40 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.549200\n",
      "  > Rotation_Wide æ£€éªŒ RÂ²: 0.3880\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Core (25-30 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 19.788554\n",
      "  > Rotation_Core æ£€éªŒ RÂ²: 0.3608\n",
      "  æµ‹è¯•é¢‘å¸¦: Rieger (140-170 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 8.104544\n",
      "  > Rieger æ£€éªŒ RÂ²: 0.0723\n",
      "  æµ‹è¯•é¢‘å¸¦: Annual (350-380 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 5.139585\n",
      "  > Annual æ£€éªŒ RÂ²: -0.9186\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_1.5_3.0y (547.875-1095.75 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 10.079142\n",
      "  > QBO_1.5_3.0y æ£€éªŒ RÂ²: 0.3098\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_2.2y (730.5-876.6 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 50282, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 5.994016\n",
      "  > QBO_2.2y æ£€éªŒ RÂ²: 0.0398\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+2 (è®­ç»ƒæˆªè‡³: 1996-08-01)\n",
      "==================================================\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Wide (20-40 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 29.679665\n",
      "  > Rotation_Wide æ£€éªŒ RÂ²: 0.5210\n",
      "  æµ‹è¯•é¢‘å¸¦: Rotation_Core (25-30 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 20.046846\n",
      "  > Rotation_Core æ£€éªŒ RÂ²: 0.4125\n",
      "  æµ‹è¯•é¢‘å¸¦: Rieger (140-170 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 8.187757\n",
      "  > Rieger æ£€éªŒ RÂ²: 0.1514\n",
      "  æµ‹è¯•é¢‘å¸¦: Annual (350-380 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 4.843152\n",
      "  > Annual æ£€éªŒ RÂ²: -0.5138\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_1.5_3.0y (547.875-1095.75 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 9.793664\n",
      "  > QBO_1.5_3.0y æ£€éªŒ RÂ²: 0.2911\n",
      "  æµ‹è¯•é¢‘å¸¦: QBO_2.2y (730.5-876.6 å¤©)\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 53904, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 6.076190\n",
      "  > QBO_2.2y æ£€éªŒ RÂ²: -0.0450\n",
      "\n",
      "\n",
      "============================================================\n",
      "      èƒ½é‡åŒ…ç»œè°ƒåˆ¶ç­›é€‰ - æœ€ç»ˆæ€»ç»“æŠ¥å‘Š\n",
      " (æ£€éªŒ Y_åŒ…ç»œ = f(X_è¡Œæ˜Ÿæ‹Ÿåˆ) åœ¨æµ‹è¯•é›†ä¸Šçš„ RÂ² åˆ†æ•°)\n",
      "============================================================\n",
      "model            M0+2    M0+3    M8+2    M8+3  Average_R2\n",
      "band_name                                                \n",
      "Rotation_Wide  0.5210  0.3880  0.3943  0.3229      0.4065\n",
      "Rotation_Core  0.4125  0.3608  0.2925  0.3428      0.3522\n",
      "QBO_1.5_3.0y   0.2911  0.3098  0.4471  0.2012      0.3123\n",
      "Rieger         0.1514  0.0723 -0.2387 -0.1263     -0.0353\n",
      "QBO_2.2y      -0.0450  0.0398 -0.3194 -0.1298     -0.1136\n",
      "Annual        -0.5138 -0.9186 -0.6341 -1.2428     -0.8273\n",
      "\n",
      "============================================================\n",
      "ç»“è®º:\n",
      "âœ… å¼ºçƒˆè¯æ®: é¢‘å¸¦ 'Rotation_Wide' (å¹³å‡RÂ²=0.4065) çš„èƒ½é‡åŒ…ç»œ\n",
      "   ä¸11å¹´è¡Œæ˜Ÿå‘¨æœŸæœ‰å¾ˆå¼ºçš„è°ƒåˆ¶å…³ç³»ã€‚\n",
      "\n",
      "ğŸ‘‰ å»ºè®®: åœ¨LGBMå…¨é¢‘ç‡æ¢³æ¨¡å‹ä¸­ï¼Œåº”é‡ç‚¹å…³æ³¨ Rotation_Wide é¢‘å¸¦çš„è°ƒåˆ¶ç‰¹å¾ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.signal import butter, sosfiltfilt, hilbert\n",
    "import lightgbm as lgb  # æˆ‘ä»¬ç”¨ä¸€ä¸ªç®€å•çš„LGBMä½œä¸ºæ£€éªŒæ¨¡å‹ f\n",
    "\n",
    "# ç¡®ä¿å¤©æ–‡å­¦åº“å¯ç”¨ (å¦‚æœLGBMä»£ç ä¹Ÿåœ¨æ­¤è¿è¡Œ)\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM å¯¼å…¥æˆåŠŸã€‚\")\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯ï¼šæœªæ‰¾åˆ° lightgbm åº“ã€‚\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    # æ£€æŸ¥ scipy (ä¿¡å·å¤„ç†åº“)\n",
    "    import scipy\n",
    "    print(f\"Scipy å¯¼å…¥æˆåŠŸ (ç‰ˆæœ¬: {scipy.__version__})ã€‚\")\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯: æœ¬è„šæœ¬éœ€è¦ scipy åº“ã€‚\")\n",
    "    print(\"è¯·å®‰è£…: pip install scipy\")\n",
    "    exit()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- æ ¸å¿ƒå‡½æ•° 1: å¸¦é€šæ»¤æ³¢å™¨ ---\n",
    "def bandpass_filter(data, lowcut_days, highcut_days, fs=1.0, order=4):\n",
    "    \"\"\"\n",
    "    åº”ç”¨é›¶ç›¸ä½å¸¦é€šæ»¤æ³¢å™¨\n",
    "    fs=1.0 æ„å‘³ç€é‡‡æ ·é—´éš”ä¸º1å¤©\n",
    "    \"\"\"\n",
    "    # å°†å‘¨æœŸï¼ˆå¤©ï¼‰è½¬æ¢ä¸ºé¢‘ç‡ï¼ˆ1/å¤©ï¼‰\n",
    "    low_freq = 1.0 / highcut_days\n",
    "    high_freq = 1.0 / lowcut_days\n",
    "    \n",
    "    # Nyquist é¢‘ç‡\n",
    "    nyq = 0.5 * fs\n",
    "    \n",
    "    # å½’ä¸€åŒ–é¢‘ç‡\n",
    "    low = low_freq / nyq\n",
    "    high = high_freq / nyq\n",
    "    \n",
    "    # ç¡®ä¿é¢‘ç‡åœ¨æœ‰æ•ˆèŒƒå›´å†…\n",
    "    low = max(low, 1e-9) \n",
    "    high = min(high, 0.9999)\n",
    "\n",
    "    if low >= high:\n",
    "        print(f\"è­¦å‘Š: é¢‘ç‡èŒƒå›´æ— æ•ˆ [{low}, {high}]ã€‚è·³è¿‡æ»¤æ³¢ã€‚\")\n",
    "        return data # è¿”å›åŸå§‹æ•°æ®\n",
    "\n",
    "    # åˆ›å»ºæ»¤æ³¢å™¨\n",
    "    sos = butter(order, [low, high], btype='band', output='sos')\n",
    "    \n",
    "    # åº”ç”¨é›¶ç›¸ä½æ»¤æ³¢å™¨\n",
    "    filtered_data = sosfiltfilt(sos, data)\n",
    "    return filtered_data\n",
    "\n",
    "# --- æ ¸å¿ƒå‡½æ•° 2: è®¡ç®—èƒ½é‡åŒ…ç»œ ---\n",
    "def get_energy_envelope(data, smoothing_window_days=365):\n",
    "    \"\"\"\n",
    "    è®¡ç®—ä¿¡å·çš„èƒ½é‡åŒ…ç»œ (å¸Œå°”ä¼¯ç‰¹å˜æ¢)ï¼Œå¹¶è¿›è¡Œå¹³æ»‘\n",
    "    \"\"\"\n",
    "    # 1. è®¡ç®—è§£æä¿¡å·\n",
    "    analytic_signal = hilbert(data)\n",
    "    \n",
    "    # 2. è®¡ç®—èƒ½é‡åŒ…ç»œ (ç¬æ—¶å¹…åº¦)\n",
    "    envelope = np.abs(analytic_signal)\n",
    "    \n",
    "    # 3. (å…³é”®) å¯¹åŒ…ç»œè¿›è¡Œå¹³æ»‘ï¼Œä»¥è§‚å¯Ÿå…¶é•¿æœŸè¶‹åŠ¿\n",
    "    #    æˆ‘ä»¬ä½¿ç”¨ä¸­å¿ƒæ»‘åŠ¨å¹³å‡\n",
    "    envelope_series = pd.Series(envelope)\n",
    "    smoothed_envelope = envelope_series.rolling(\n",
    "        window=smoothing_window_days, \n",
    "        center=True, \n",
    "        min_periods=int(smoothing_window_days * 0.1) # å…è®¸è¾¹ç¼˜\n",
    "    ).mean()\n",
    "    \n",
    "    return smoothed_envelope\n",
    "\n",
    "# --- æ ¸å¿ƒå‡½æ•° 3: è¿è¡Œè°ƒåˆ¶æ£€éªŒ ---\n",
    "def run_modulation_test(\n",
    "    data_full, model_name, train_end_date, test_end_date, \n",
    "    band_name, freq_band_days, envelope_smoothing_days=365\n",
    "):\n",
    "    \"\"\"\n",
    "    æ£€éªŒä¸€ä¸ªé¢‘å¸¦(band)çš„èƒ½é‡åŒ…ç»œæ˜¯å¦è¢«11å¹´å‘¨æœŸ(æ‹ŸåˆSSN)è°ƒåˆ¶\n",
    "    \"\"\"\n",
    "    \n",
    "    target_residual_column = f'æ®‹å·®_{model_name}'\n",
    "    planetary_fit_column = f'æ‹ŸåˆSSN_{model_name}'\n",
    "\n",
    "    print(f\"  æµ‹è¯•é¢‘å¸¦: {band_name} ({freq_band_days[0]}-{freq_band_days[1]} å¤©)\")\n",
    "\n",
    "    # 1. å‡†å¤‡æ•°æ®\n",
    "    data = data_full[['æ—¥æœŸ', target_residual_column, planetary_fit_column]].copy()\n",
    "    \n",
    "    # ç­›é€‰å‡ºç”¨äºåˆ†æçš„å¹²å‡€æ•°æ® (æ‹ŸåˆSSN å’Œ æ®‹å·® éƒ½å¿…é¡»å­˜åœ¨)\n",
    "    data_clean = data.dropna(subset=[target_residual_column, planetary_fit_column])\n",
    "    if len(data_clean) < 5000: # éœ€è¦è¶³å¤Ÿæ•°æ®æ¥æ»¤æ³¢\n",
    "        print(f\"  è­¦å‘Š: {model_name} çš„å¹²å‡€æ•°æ®ä¸è¶³ ({len(data_clean)}è¡Œ)ã€‚\")\n",
    "        return None\n",
    "\n",
    "    # --- ä¿¡å·å¤„ç† ---\n",
    "    \n",
    "    # 2. Y (æ®‹å·®) -> å¸¦é€šæ»¤æ³¢\n",
    "    Y_filtered = bandpass_filter(\n",
    "        data_clean[target_residual_column].values, \n",
    "        freq_band_days[0], \n",
    "        freq_band_days[1]\n",
    "    )\n",
    "    \n",
    "    # 3. Y_filtered -> èƒ½é‡åŒ…ç»œ\n",
    "    Y_envelope = get_energy_envelope(\n",
    "        Y_filtered, \n",
    "        smoothing_window_days=envelope_smoothing_days\n",
    "    )\n",
    "    \n",
    "    data_clean.loc[:, 'Y_Envelope'] = Y_envelope\n",
    "    \n",
    "    # 4. X (é©±åŠ¨åŠ›) -> ä¹Ÿè¿›è¡Œå¹³æ»‘\n",
    "    #    æˆ‘ä»¬æ¯”è¾ƒçš„æ˜¯ä¸¤ä¸ªæ…¢å˜é‡ï¼šåŒ…ç»œçš„æ…¢å˜åŒ– vs 11å¹´å‘¨æœŸçš„æ…¢å˜åŒ–\n",
    "    data_clean.loc[:, 'X_Driver_Smooth'] = data_clean[planetary_fit_column].rolling(\n",
    "        window=envelope_smoothing_days, \n",
    "        center=True, \n",
    "        min_periods=int(envelope_smoothing_days * 0.1)\n",
    "    ).mean()\n",
    "\n",
    "    # --- å»ºç«‹æ£€éªŒæ¨¡å‹ ---\n",
    "    \n",
    "    # 5. å†æ¬¡æ¸…ç† (å¹³æ»‘å’Œæ»¤æ³¢ä¼šäº§ç”Ÿæ–°çš„NaN)\n",
    "    data_model = data_clean.dropna(subset=['Y_Envelope', 'X_Driver_Smooth'])\n",
    "    \n",
    "    # 6. å®šä¹‰ è®­ç»ƒ/æµ‹è¯• æ©ç \n",
    "    train_mask = (data_model['æ—¥æœŸ'] <= train_end_date)\n",
    "    test_mask = (data_model['æ—¥æœŸ'] > train_end_date) & (data_model['æ—¥æœŸ'] <= test_end_date)\n",
    "\n",
    "    X_train = data_model.loc[train_mask, ['X_Driver_Smooth']]\n",
    "    Y_train = data_model.loc[train_mask, 'Y_Envelope']\n",
    "    X_test = data_model.loc[test_mask, ['X_Driver_Smooth']]\n",
    "    Y_test = data_model.loc[test_mask, 'Y_Envelope']\n",
    "\n",
    "    if len(X_train) == 0 or len(X_test) == 0:\n",
    "        print(f\"  é”™è¯¯: é¢‘å¸¦ {band_name} çš„è®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©ºã€‚\")\n",
    "        return None\n",
    "\n",
    "    # 7. æ‹Ÿåˆä¸€ä¸ªç®€å•çš„LGBM: Y_Envelope = f(X_Driver_Smooth)\n",
    "    #    æˆ‘ä»¬ç”¨å®ƒæ¥æ•æ‰å¯èƒ½çš„éçº¿æ€§å…³ç³»\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # ä½¿ç”¨ä¸€ä¸ªéå¸¸ç®€å•çš„ã€é˜²æ­¢è¿‡æ‹Ÿåˆçš„LGBM\n",
    "    lgbm_tester = lgb.LGBMRegressor(\n",
    "        n_estimators=50,\n",
    "        num_leaves=5,\n",
    "        learning_rate=0.05,\n",
    "        random_state=42,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    lgbm_tester.fit(X_train_scaled, Y_train)\n",
    "    \n",
    "    # 8. åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° RÂ²\n",
    "    Y_pred = lgbm_tester.predict(X_test_scaled)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "    \n",
    "    print(f\"  > {band_name} æ£€éªŒ RÂ²: {r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'band_name': band_name,\n",
    "        'low_days': freq_band_days[0],\n",
    "        'high_days': freq_band_days[1],\n",
    "        'r2_score': r2\n",
    "    }\n",
    "\n",
    "\n",
    "# === ä¸»æ‰§è¡Œè„šæœ¬ ===\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # --- 1. å®šä¹‰è¦ç­›é€‰çš„é¢‘å¸¦ (å•ä½: å¤©) ---\n",
    "    #    æˆ‘ä»¬ç­›é€‰çŸ­æœŸå’Œä¸­æœŸé¢‘ç‡\n",
    "    BANDS_TO_TEST = {\n",
    "        # å¤ªé˜³è‡ªè½¬ (å®½å¸¦)\n",
    "        'Rotation_Wide': [20, 40],\n",
    "        # å¤ªé˜³è‡ªè½¬ (æ ¸å¿ƒ)\n",
    "        'Rotation_Core': [25, 30],\n",
    "        # é‡Œæ ¼å‘¨æœŸ\n",
    "        'Rieger': [140, 170],\n",
    "        # å¹´åº¦å‘¨æœŸ\n",
    "        'Annual': [350, 380],\n",
    "        # QBO (å‡†ä¸¤å¹´æŒ¯è¡)\n",
    "        'QBO_1.5_3.0y': [1.5 * 365.25, 3.0 * 365.25],\n",
    "        # QBO (çª„å¸¦)\n",
    "        'QBO_2.2y': [2.0 * 365.25, 2.4 * 365.25]\n",
    "        # æ³¨æ„: 22yçš„Haleå‘¨æœŸå¤ªé•¿äº†ï¼Œä¸é€‚åˆåšèƒ½é‡åŒ…ç»œæ£€éªŒ (å®ƒæœ¬èº«å°±æ˜¯é©±åŠ¨åŠ›å°ºåº¦)\n",
    "    }\n",
    "\n",
    "    # --- 2. å®šä¹‰æ¨¡å‹åˆ†å‰²ç‚¹ ---\n",
    "    model_splits = {\n",
    "        'M8+2': '1996-08-01', \n",
    "        'M8+3': '1986-08-01',\n",
    "        'M0+3': '1986-09-01', \n",
    "        'M0+2': '1996-08-01'\n",
    "    }\n",
    "    \n",
    "    test_end_date = '2019-11-30'\n",
    "    \n",
    "    # --- 3. åŠ è½½æ•°æ® ---\n",
    "    try:\n",
    "        data_source_file = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\"\n",
    "        print(f\"åŠ è½½æºæ•°æ®: {data_source_file}\")\n",
    "        full_data = pd.read_csv(data_source_file, parse_dates=['æ—¥æœŸ'])\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½é”™è¯¯ï¼šæ— æ³•è¯»å– {data_source_file}ã€‚é”™è¯¯: {e}\")\n",
    "        exit()\n",
    "\n",
    "    \n",
    "    # --- 4. å¼€å§‹ç­›é€‰ ---\n",
    "    all_results = []\n",
    "    \n",
    "    print(\"\\n=== å¼€å§‹ç­›é€‰â€œèƒ½é‡åŒ…ç»œè°ƒåˆ¶â€çš„ç‰©ç†é¢‘å¸¦ ===\")\n",
    "    \n",
    "    for model_name, split_date in model_splits.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"å¤„ç†æ¨¡å‹: {model_name} (è®­ç»ƒæˆªè‡³: {split_date})\")\n",
    "        print(f\"{'='*50}\")\n",
    "\n",
    "        # æ£€æŸ¥æ‰€éœ€åˆ—æ˜¯å¦å­˜åœ¨\n",
    "        target_col = f'æ®‹å·®_{model_name}'\n",
    "        driver_col = f'æ‹ŸåˆSSN_{model_name}'\n",
    "        if target_col not in full_data.columns or driver_col not in full_data.columns:\n",
    "            print(f\"è­¦å‘Š: ç¼ºå°‘ {target_col} æˆ– {driver_col}ã€‚è·³è¿‡æ­¤æ¨¡å‹ã€‚\")\n",
    "            continue\n",
    "\n",
    "        for band_name, freq_band_days in BANDS_TO_TEST.items():\n",
    "            result = run_modulation_test(\n",
    "                data_full=full_data,\n",
    "                model_name=model_name,\n",
    "                train_end_date=split_date,\n",
    "                test_end_date=test_end_date,\n",
    "                band_name=band_name,\n",
    "                freq_band_days=freq_band_days,\n",
    "                envelope_smoothing_days=365 # ä½¿ç”¨1å¹´å¹³æ»‘çª—å£\n",
    "            )\n",
    "            if result:\n",
    "                all_results.append(result)\n",
    "\n",
    "    # --- 5. æ€»ç»“æŠ¥å‘Š ---\n",
    "    if not all_results:\n",
    "        print(\"\\næ‰€æœ‰åˆ†æå‡å¤±è´¥ã€‚\")\n",
    "        exit()\n",
    "\n",
    "    print(\"\\n\\n\" + \"=\"*60)\n",
    "    print(\"      èƒ½é‡åŒ…ç»œè°ƒåˆ¶ç­›é€‰ - æœ€ç»ˆæ€»ç»“æŠ¥å‘Š\")\n",
    "    print(\" (æ£€éªŒ Y_åŒ…ç»œ = f(X_è¡Œæ˜Ÿæ‹Ÿåˆ) åœ¨æµ‹è¯•é›†ä¸Šçš„ RÂ² åˆ†æ•°)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # è®¡ç®—æ¯ä¸ªé¢‘å¸¦åœ¨4ä¸ªæ¨¡å‹ä¸Šçš„å¹³å‡ RÂ²\n",
    "    summary = results_df.pivot_table(\n",
    "        index='band_name', \n",
    "        columns='model', \n",
    "        values='r2_score'\n",
    "    )\n",
    "    \n",
    "    # è®¡ç®—å¹³å‡RÂ²å¹¶æ’åº\n",
    "    summary['Average_R2'] = summary.mean(axis=1)\n",
    "    summary = summary.sort_values(by='Average_R2', ascending=False)\n",
    "    \n",
    "    print(summary.to_string(float_format=\"%.4f\"))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ç»“è®º:\")\n",
    "    top_band = summary.index[0]\n",
    "    top_r2 = summary.iloc[0]['Average_R2']\n",
    "    \n",
    "    if top_r2 > 0.05:\n",
    "        print(f\"âœ… å¼ºçƒˆè¯æ®: é¢‘å¸¦ '{top_band}' (å¹³å‡RÂ²={top_r2:.4f}) çš„èƒ½é‡åŒ…ç»œ\")\n",
    "        print(\"   ä¸11å¹´è¡Œæ˜Ÿå‘¨æœŸæœ‰å¾ˆå¼ºçš„è°ƒåˆ¶å…³ç³»ã€‚\")\n",
    "        print(f\"\\nğŸ‘‰ å»ºè®®: åœ¨LGBMå…¨é¢‘ç‡æ¢³æ¨¡å‹ä¸­ï¼Œåº”é‡ç‚¹å…³æ³¨ {top_band} é¢‘å¸¦çš„è°ƒåˆ¶ç‰¹å¾ã€‚\")\n",
    "    elif top_r2 > 0.01:\n",
    "        print(f\"âœ… æœ‰æ•ˆè¯æ®: é¢‘å¸¦ '{top_band}' (å¹³å‡RÂ²={top_r2:.4f}) æ˜¾ç¤ºäº†å¾®å¼±ä½†ç¨³å®šçš„è°ƒåˆ¶å…³ç³»ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ è¯æ®ä¸è¶³: æ‰€æœ‰é¢‘å¸¦çš„èƒ½é‡åŒ…ç»œä¸11å¹´å‘¨æœŸçš„ç›¸å…³æ€§ (RÂ²) éƒ½éå¸¸ä½ã€‚\")\n",
    "        print(\"   LGBMä¸­çš„ 'Mod_' è°ƒåˆ¶ç‰¹å¾å¯èƒ½æ•ˆæœæœ‰é™æˆ–ä¾èµ–äºå…¶ä»–æœºåˆ¶ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaeb146-7367-4ee2-828c-7f249a600247",
   "metadata": {},
   "source": [
    "# èƒ½é‡åŒ…ç»œç­›é€‰ï¼Œåˆæ­¥æ‹Ÿåˆç»“æœä¸ä½³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ffc7b8-bc18-4530-a970-d6966f037802",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM å¯¼å…¥æˆåŠŸã€‚\n",
      "=== è¿è¡Œ LGBM (ç‰©ç†ç­›é€‰ä¼˜åŒ–ç‰ˆ) ===\n",
      "ç­–ç•¥: åŸºç¡€å…¨é¢‘ç‡æ¢³ + (QBO+Rotation)è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\n",
      "\n",
      "åŠ è½½æºæ•°æ®: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM ä¼˜åŒ–ç‰ˆ (QBO+Rotationè°ƒåˆ¶): M8+2 ===\n",
      "1. ç”Ÿæˆ B0 + å…¨åŸºç¡€é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "åŸºç¡€ç‰¹å¾: 30 ä¸ª\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "ç­›é€‰å‡º 18 ä¸ªç‰¹å¾è¿›è¡Œè°ƒåˆ¶ (åŸºäºèƒ½é‡åŒ…ç»œæ£€éªŒ)ã€‚\n",
      "æ€»ç‰¹å¾æ•°: 48 (30 åŸºç¡€ + 18 è°ƒåˆ¶)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (ä¼˜åŒ–ç‰ˆ)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 51378, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.017457\n",
      "\n",
      "LGBM ä¼˜åŒ–ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): -0.0935\n",
      "âŒ RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.0015805316449195594, 'n_estimators': 800, 'num_leaves': 19, 'reg_alpha': 0.13339802460402347, 'reg_lambda': 0.1, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Hale_22y_cos            2574\n",
      "Hale_22y_sin            2340\n",
      "Mod_QBO_2.7y_cos        1496\n",
      "Mod_QBO_2.2y_sin        1161\n",
      "Mod_QBO_2.7y_sin        1149\n",
      "Mod_QBO_2.2y_cos        1037\n",
      "Mod_QBO_1.7y_cos         865\n",
      "Mod_QBO_1.7y_sin         516\n",
      "QBO_2.7y_sin             359\n",
      "QBO_2.7y_cos             341\n",
      "QBO_2.2y_sin             272\n",
      "QBO_1.7y_cos             248\n",
      "QBO_1.7y_sin             228\n",
      "Mod_Rotation_28d_cos     215\n",
      "Annual_360d_cos          209\n",
      "Mod_Rotation_27d_sin     168\n",
      "Mod_Rotation_30d_cos     162\n",
      "Annual_360d_sin          155\n",
      "QBO_2.2y_cos             112\n",
      "Mod_Rotation_28d_sin     111\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 10 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models_Optimized/M8+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+3 (è®­ç»ƒç»“æŸäº 1986-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM ä¼˜åŒ–ç‰ˆ (QBO+Rotationè°ƒåˆ¶): M8+3 ===\n",
      "1. ç”Ÿæˆ B0 + å…¨åŸºç¡€é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "åŸºç¡€ç‰¹å¾: 30 ä¸ª\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "ç­›é€‰å‡º 18 ä¸ªç‰¹å¾è¿›è¡Œè°ƒåˆ¶ (åŸºäºèƒ½é‡åŒ…ç»œæ£€éªŒ)ã€‚\n",
      "æ€»ç‰¹å¾æ•°: 48 (30 åŸºç¡€ + 18 è°ƒåˆ¶)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47725, æµ‹è¯•12174\n",
      "è®­ç»ƒLGBM (ä¼˜åŒ–ç‰ˆ)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 47725, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.008678\n",
      "\n",
      "LGBM ä¼˜åŒ–ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.1037\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.002667322993530731, 'n_estimators': 800, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 10.024469484847398, 'subsample': 0.8480558013358933})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Hale_22y_cos            663\n",
      "Mod_QBO_2.7y_cos        540\n",
      "Mod_QBO_2.7y_sin        478\n",
      "Hale_22y_sin            451\n",
      "Mod_QBO_1.7y_cos        197\n",
      "Mod_QBO_2.2y_cos        193\n",
      "Mod_QBO_2.2y_sin        179\n",
      "Mod_Rotation_27d_sin    108\n",
      "Mod_Rotation_28d_cos     84\n",
      "Mod_Rotation_27d_cos     56\n",
      "Mod_Rotation_30d_cos     47\n",
      "Mod_Rotation_25d_sin     29\n",
      "Mod_QBO_1.7y_sin         28\n",
      "Mod_Rotation_26d_sin     28\n",
      "Mod_Rotation_30d_sin     26\n",
      "Mod_Rotation_26d_cos     24\n",
      "Mod_Rotation_29d_cos     17\n",
      "Mod_Rotation_29d_sin     14\n",
      "Mod_Rotation_25d_cos      7\n",
      "Mod_Rotation_28d_sin      7\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 18 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models_Optimized/M8+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+3 (è®­ç»ƒç»“æŸäº 1986-09-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM ä¼˜åŒ–ç‰ˆ (QBO+Rotationè°ƒåˆ¶): M0+3 ===\n",
      "1. ç”Ÿæˆ B0 + å…¨åŸºç¡€é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "åŸºç¡€ç‰¹å¾: 30 ä¸ª\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "ç­›é€‰å‡º 18 ä¸ªç‰¹å¾è¿›è¡Œè°ƒåˆ¶ (åŸºäºèƒ½é‡åŒ…ç»œæ£€éªŒ)ã€‚\n",
      "æ€»ç‰¹å¾æ•°: 48 (30 åŸºç¡€ + 18 è°ƒåˆ¶)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47756, æµ‹è¯•12143\n",
      "è®­ç»ƒLGBM (ä¼˜åŒ–ç‰ˆ)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009077 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002100 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009382 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008772 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001924 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002435 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002133 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002237 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009145 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009398 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002065 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002270 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001971 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002169 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009152 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008629 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002052 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009101 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002112 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002068 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002363 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009276 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008759 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002495 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002239 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009047 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002054 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008422 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008970 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009005 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002282 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002310 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002053 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002059 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002400 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002370 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002253 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009785 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008851 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009168 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002353 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002201 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010186 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002247 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002077 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002347 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002159 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002288 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002003 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002267 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002082 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002173 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002345 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002421 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002441 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008742 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.025932\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.014757\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002324 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009478 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.022946\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002121 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38229, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.060478\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002202 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008747 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002107 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002820 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.031657\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.044124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002023 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.047591\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.021534\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38199, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.042467\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38228, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.029099\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002186 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 47756, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004984\n",
      "\n",
      "LGBM ä¼˜åŒ–ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0558\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.0022453778970967122, 'n_estimators': 436, 'num_leaves': 30, 'reg_alpha': 0.1, 'reg_lambda': 20.0, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_QBO_2.7y_sin    1308\n",
      "Mod_QBO_2.7y_cos    1254\n",
      "Hale_22y_cos        1155\n",
      "Mod_QBO_2.2y_cos    1126\n",
      "Mod_QBO_2.2y_sin    1106\n",
      "Mod_QBO_1.7y_cos     974\n",
      "Mod_QBO_1.7y_sin     717\n",
      "Hale_22y_sin         670\n",
      "QBO_2.7y_sin         575\n",
      "QBO_2.7y_cos         533\n",
      "QBO_2.2y_sin         371\n",
      "Annual_360d_cos      350\n",
      "QBO_2.2y_cos         315\n",
      "QBO_1.7y_cos         307\n",
      "QBO_1.7y_sin         299\n",
      "Annual_370d_cos      299\n",
      "Annual_370d_sin      281\n",
      "Annual_365d_cos      241\n",
      "Annual_360d_sin      239\n",
      "B0                   124\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 6 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models_Optimized/M0+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM ä¼˜åŒ–ç‰ˆ (QBO+Rotationè°ƒåˆ¶): M0+2 ===\n",
      "1. ç”Ÿæˆ B0 + å…¨åŸºç¡€é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "åŸºç¡€ç‰¹å¾: 30 ä¸ª\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "ç­›é€‰å‡º 18 ä¸ªç‰¹å¾è¿›è¡Œè°ƒåˆ¶ (åŸºäºèƒ½é‡åŒ…ç»œæ£€éªŒ)ã€‚\n",
      "æ€»ç‰¹å¾æ•°: 48 (30 åŸºç¡€ + 18 è°ƒåˆ¶)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (ä¼˜åŒ–ç‰ˆ)...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 51378, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.012865\n",
      "\n",
      "LGBM ä¼˜åŒ–ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): -0.0542\n",
      "âŒ RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.0024649478068009384, 'n_estimators': 800, 'num_leaves': 5, 'reg_alpha': 20.0, 'reg_lambda': 0.1, 'subsample': 0.7795551697188506})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_QBO_2.7y_cos        645\n",
      "Hale_22y_cos            496\n",
      "Mod_QBO_2.2y_sin        454\n",
      "Mod_QBO_2.7y_sin        357\n",
      "Mod_QBO_2.2y_cos        311\n",
      "Mod_QBO_1.7y_cos        194\n",
      "Hale_22y_sin            182\n",
      "Mod_QBO_1.7y_sin        157\n",
      "Mod_Rotation_30d_sin     76\n",
      "Mod_Rotation_30d_cos     56\n",
      "Mod_Rotation_27d_cos     53\n",
      "QBO_2.7y_sin             36\n",
      "Mod_Rotation_27d_sin     34\n",
      "QBO_2.7y_cos             30\n",
      "Mod_Rotation_28d_cos     26\n",
      "Mod_Rotation_28d_sin     23\n",
      "QBO_1.7y_sin             20\n",
      "Mod_Rotation_26d_sin     16\n",
      "QBO_2.2y_cos             11\n",
      "Annual_365d_cos           5\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 13 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models_Optimized/M0+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "============================================================\n",
      "ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„ä¼˜åŒ–ç‰ˆäºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ_Optimized.csv\n",
      "ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« 73780 è¡Œæ•°æ®ã€‚\n",
      "\n",
      "============================================================\n",
      "LGBM ç‰©ç†ç­›é€‰ä¼˜åŒ–ç‰ˆ æ€»ç»“\n",
      "============================================================\n",
      "model  r2_score  n_feat_total  n_feat_mod  top_20_mod  time(s)\n",
      " M8+2   -0.0935            48          18          10 128.9952\n",
      " M8+3    0.1037            48          18          18 109.2244\n",
      " M0+3    0.0558            48          18           6 114.1031\n",
      " M0+2   -0.0542            48          18          13 107.5876\n",
      "\n",
      "å¹³å‡RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0030\n",
      "âŒ æ³¨æ„: ä¼˜åŒ–ç‰ˆRÂ² (0.0030) ä½äºåŸºçº¿ (çº¦ 0.12)ã€‚\n",
      "   è¿™å¯èƒ½æ„å‘³ç€è¢«åˆ é™¤çš„ç‰¹å¾ä¸­ä»æœ‰å¾®å¼±ä¿¡å·ã€‚\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008803 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008859 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002409 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002429 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009947 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009708 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001985 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002315 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008883 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001941 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002493 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009187 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008637 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008740 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002412 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002502 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002079 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002180 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002506 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002058 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002535 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002389 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002381 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002386 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002411 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009904 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010061 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002304 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009390 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009814 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002378 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002309 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002339 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001962 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008975 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002367 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002452 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002174 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002346 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009818 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002251 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008855 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008827 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002140 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001907 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008615 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008873 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008836 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002383 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008654 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001944 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001921 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002278 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001935 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002171 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002398 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009736 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009815 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001961 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001929 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009699 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.005938\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009624 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 38260, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.030124\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.015688\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 38230, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017955\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008718 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008868 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 38016, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.017037\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12237\n",
      "[LightGBM] [Info] Number of data points in the train set: 38259, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.002272\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.032928\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002313 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011334 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009849 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 41121, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.011717\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12239\n",
      "[LightGBM] [Info] Number of data points in the train set: 40938, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score -0.004689\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009782 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12238\n",
      "[LightGBM] [Info] Number of data points in the train set: 41151, number of used features: 48\n",
      "[LightGBM] [Info] Start training from score 0.022762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM å¯¼å…¥æˆåŠŸã€‚\")\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯ï¼šæœªæ‰¾åˆ° lightgbm åº“ã€‚\")\n",
    "    exit()\n",
    "\n",
    "try:\n",
    "    from astropy.time import Time\n",
    "    import astropy.units as u\n",
    "    from sunpy.coordinates import sun\n",
    "except ImportError:\n",
    "    print(\"ç¼ºå°‘å¤©æ–‡å­¦åº“\")\n",
    "    exit()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_lgbm_optimized_comb_validation( # é‡å‘½åå‡½æ•°\n",
    "    data_full, model_name, train_start_date, train_end_date, test_end_date\n",
    "):\n",
    "    \"\"\"\n",
    "    è¿è¡Œ LGBM (ä¼˜åŒ–ç‰ˆ)\n",
    "    - ç‰¹å¾: B0 + æ‰€æœ‰åŸºç¡€å‘¨æœŸ\n",
    "    - è°ƒåˆ¶: ä»…è°ƒåˆ¶ QBO å’Œ Rotation (åŸºäºèƒ½é‡åŒ…ç»œç­›é€‰)\n",
    "    - Yå˜æ¢: QuantileTransformer\n",
    "    - è°ƒä¼˜: å¼ºæ­£åˆ™åŒ–\n",
    "    - åŠŸèƒ½: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸé¢„æµ‹\n",
    "    \"\"\"\n",
    "    \n",
    "    data = data_full.copy() \n",
    "    target_residual_column = f'æ®‹å·®_{model_name}'\n",
    "    planetary_fit_column = f'æ‹ŸåˆSSN_{model_name}'\n",
    "    os.makedirs(\"LGBM_Models_Optimized\", exist_ok=True) # ä¿å­˜åˆ°æ–°ç›®å½•\n",
    "    \n",
    "    print(f\"\\n=== LGBM ä¼˜åŒ–ç‰ˆ (QBO+Rotationè°ƒåˆ¶): {model_name} ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if target_residual_column not in data.columns or planetary_fit_column not in data.columns:\n",
    "        print(f\"é”™è¯¯: ç¼ºå°‘åˆ— {target_residual_column} æˆ– {planetary_fit_column}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 1. ç‰¹å¾å·¥ç¨‹ï¼šB0 + å…¨é¢‘ç‡æ¢³ (åœ¨æ‰€æœ‰æ—¥æœŸä¸Š) ---\n",
    "    print(\"1. ç”Ÿæˆ B0 + å…¨åŸºç¡€é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    times_astropy = Time(data['æ—¥æœŸ'].values)\n",
    "    \n",
    "    original_feature_names = []\n",
    "    \n",
    "    # B0 (æ—¥é¢ä¸­å¿ƒçº¬åº¦)\n",
    "    b0_deg = sun.B0(times_astropy).deg\n",
    "    data['B0'] = b0_deg\n",
    "    data['B0_sq'] = b0_deg ** 2\n",
    "    original_feature_names.extend(['B0', 'B0_sq'])\n",
    "    \n",
    "    days_since_start = (data['æ—¥æœŸ'] - data['æ—¥æœŸ'].min()).dt.days\n",
    "    \n",
    "    # 1. Hale (22y)\n",
    "    hale_rad = 2 * np.pi * days_since_start / (22.0 * 365.25)\n",
    "    data['Hale_22y_sin'] = np.sin(hale_rad)\n",
    "    data['Hale_22y_cos'] = np.cos(hale_rad)\n",
    "    original_feature_names.extend(['Hale_22y_sin', 'Hale_22y_cos'])\n",
    "\n",
    "    # 2. QBO (1.5y - 3y)\n",
    "    qbo_periods = [1.7, 2.2, 2.7] \n",
    "    for p in qbo_periods:\n",
    "        rad = 2 * np.pi * days_since_start / (p * 365.25)\n",
    "        name = f'QBO_{p:.1f}y'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 3. Annual (1y)\n",
    "    annual_periods = [360, 365.25, 370] \n",
    "    for p in annual_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Annual_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 4. Rieger (154d)\n",
    "    rieger_rad = 2 * np.pi * days_since_start / 154\n",
    "    data['Rieger_154d_sin'] = np.sin(rieger_rad)\n",
    "    data['Rieger_154d_cos'] = np.cos(rieger_rad)\n",
    "    original_feature_names.extend(['Rieger_154d_sin', 'Rieger_154d_cos'])\n",
    "\n",
    "    # 5. Rotation (25d-30d)\n",
    "    rotation_periods = [25, 26, 27, 28, 29, 30] \n",
    "    for p in rotation_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Rotation_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "    \n",
    "    print(f\"åŸºç¡€ç‰¹å¾: {len(original_feature_names)} ä¸ª\")\n",
    "\n",
    "    # --- 2. è°ƒåˆ¶ç‰¹å¾å·¥ç¨‹ (é‡æ„) ---\n",
    "    print(\"2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    \n",
    "    train_mask_dates = (data['æ—¥æœŸ'] >= '1855-12-02') & (data['æ—¥æœŸ'] <= train_end_date)\n",
    "    train_mask_clean = train_mask_dates & data[target_residual_column].notna() & data[planetary_fit_column].notna()\n",
    "    \n",
    "    if train_mask_clean.sum() == 0:\n",
    "        print(f\"é”™è¯¯ï¼šåœ¨ {train_start_date} å’Œ {train_end_date} ä¹‹é—´æ²¡æœ‰å¹²å‡€çš„è®­ç»ƒæ•°æ®ã€‚\")\n",
    "        return None, None\n",
    "        \n",
    "    planetary_fit_values_train = data.loc[train_mask_clean, [planetary_fit_column]]\n",
    "    scaler_fit = StandardScaler()\n",
    "    scaler_fit.fit(planetary_fit_values_train)\n",
    "    \n",
    "    planetary_fit_values_full = data[[planetary_fit_column]].fillna(0) \n",
    "    data['Planetary_Scaled'] = scaler_fit.transform(planetary_fit_values_full).flatten()\n",
    "    \n",
    "    # --- å…³é”®ä¿®æ”¹ï¼šåŸºäºèƒ½é‡åŒ…ç»œç­›é€‰ç»“æœ ---\n",
    "    #    åªä¸º Rotation å’Œ QBO åˆ›å»ºè°ƒåˆ¶ç‰¹å¾\n",
    "    \n",
    "    # å®šä¹‰å…è®¸è¢«è°ƒåˆ¶çš„åŸºç¡€ç‰¹å¾åç§°ï¼ˆå‰ç¼€ï¼‰\n",
    "    modulation_allow_list = ['QBO_', 'Rotation_']\n",
    "    \n",
    "    features_to_modulate = []\n",
    "    for feat_name in original_feature_names:\n",
    "        # æ£€æŸ¥ç‰¹å¾åæ˜¯å¦ä»¥ 'QBO_' æˆ– 'Rotation_' å¼€å¤´\n",
    "        if any(feat_name.startswith(prefix) for prefix in modulation_allow_list):\n",
    "            features_to_modulate.append(feat_name)\n",
    "\n",
    "    print(f\"ç­›é€‰å‡º {len(features_to_modulate)} ä¸ªç‰¹å¾è¿›è¡Œè°ƒåˆ¶ (åŸºäºèƒ½é‡åŒ…ç»œæ£€éªŒ)ã€‚\")\n",
    "    \n",
    "    # d. åˆ›å»ºè°ƒåˆ¶ç‰¹å¾ (ä»…é™å…è®¸çš„åˆ—è¡¨)\n",
    "    modulation_feature_names = []\n",
    "    for feature in features_to_modulate: # <--- åªå¾ªç¯ç­›é€‰åçš„å­é›†\n",
    "        new_feature_name = f'Mod_{feature}'\n",
    "        data.loc[:, new_feature_name] = data['Planetary_Scaled'] * data[feature]\n",
    "        modulation_feature_names.append(new_feature_name)\n",
    "    \n",
    "    # --- ç»“æŸä¿®æ”¹ ---\n",
    "    \n",
    "    feature_names = original_feature_names + modulation_feature_names\n",
    "    print(f\"æ€»ç‰¹å¾æ•°: {len(feature_names)} (30 åŸºç¡€ + {len(modulation_feature_names)} è°ƒåˆ¶)\")\n",
    "    \n",
    "    # --- 3. æ•°æ®åˆ†å‰²ä¸å˜æ¢ (ç”¨äºè®­ç»ƒ) ---\n",
    "    data_clean = data.dropna(subset=[target_residual_column] + feature_names)\n",
    "    \n",
    "    X = data_clean[feature_names]\n",
    "    Y_raw = data_clean[target_residual_column]\n",
    "    groups = data_clean['æ—¥æœŸ'].dt.year\n",
    "    dates = data_clean['æ—¥æœŸ']\n",
    "    \n",
    "    train_mask = (dates >= train_start_date) & (dates <= train_end_date)\n",
    "    test_start_date_dt = pd.to_datetime(train_end_date) + pd.Timedelta(days=1)\n",
    "    test_mask = (dates >= test_start_date_dt) & (dates <= test_end_date)\n",
    "    \n",
    "    X_train_raw = X[train_mask]\n",
    "    Y_train_raw = Y_raw[train_mask]\n",
    "    X_test_raw = X[test_mask]\n",
    "    Y_test_raw = Y_raw[test_mask]\n",
    "    groups_train = groups[train_mask]\n",
    "    \n",
    "    if len(X_train_raw) == 0 or len(X_test_raw) == 0:\n",
    "        print(\"é”™è¯¯ï¼šè®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º\")\n",
    "        return None, None\n",
    "\n",
    "    # a. Fit X å˜æ¢\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_train = feature_scaler.fit_transform(X_train_raw)\n",
    "    X_test = feature_scaler.transform(X_test_raw)\n",
    "\n",
    "    # b. Fit Y å˜æ¢\n",
    "    print(\"åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\")\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "    Y_train = target_transformer.fit_transform(Y_train_raw.values.reshape(-1, 1)).flatten()\n",
    "    Y_test = target_transformer.transform(Y_test_raw.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(f\"æ•°æ®: è®­ç»ƒ{len(X_train)}, æµ‹è¯•{len(X_test)}\")\n",
    "    \n",
    "    # --- 4. è´å¶æ–¯ä¼˜åŒ– - LGBM (å¼ºæ­£åˆ™åŒ–) ---\n",
    "    n_splits = max(2, min(5, groups_train.nunique()))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    search_spaces = {\n",
    "        'n_estimators': Integer(100, 800),\n",
    "        'num_leaves': Integer(5, 30),\n",
    "        'learning_rate': Real(1e-3, 0.1, 'log-uniform'),\n",
    "        'reg_alpha': Real(0.1, 20.0, 'log-uniform'), \n",
    "        'reg_lambda': Real(0.1, 20.0, 'log-uniform'),\n",
    "        'subsample': Real(0.7, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.7, 1.0, 'uniform')\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMRegressor(random_state=42, n_jobs=1, \n",
    "                                  objective='regression_l1')\n",
    "\n",
    "    opt_lgbm = BayesSearchCV(\n",
    "        lgb_model, \n",
    "        search_spaces, \n",
    "        n_iter=30, \n",
    "        cv=gkf, \n",
    "        n_jobs=-1,\n",
    "        random_state=42, \n",
    "        scoring='r2'\n",
    "    )\n",
    "    \n",
    "    print(\"è®­ç»ƒLGBM (ä¼˜åŒ–ç‰ˆ)...\")\n",
    "    opt_lgbm.fit(X_train, Y_train, groups=groups_train)\n",
    "    \n",
    "    # --- 5. ç»“æœåˆ†æ ---\n",
    "    best_model = opt_lgbm.best_estimator_\n",
    "    Y_pred_test = best_model.predict(X_test)\n",
    "    final_r2 = r2_score(Y_test, Y_pred_test) \n",
    "    \n",
    "    print(f\"\\nLGBM ä¼˜åŒ–ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): {final_r2:.4f}\")\n",
    "    if final_r2 > 0:\n",
    "        print(\"âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\")\n",
    "        \n",
    "    print(f\"æœ€ä½³å‚æ•°: {opt_lgbm.best_params_}\")\n",
    "    \n",
    "    importances = pd.Series(best_model.feature_importances_, index=feature_names)\n",
    "    print(\"\\nç‰¹å¾é‡è¦æ€§ (Top 20):\")\n",
    "    top_features = importances.sort_values(ascending=False).head(20) \n",
    "    print(top_features.to_string())\n",
    "    \n",
    "    mod_features_in_top = [f for f in top_features.index if f.startswith('Mod_')]\n",
    "    print(f\"\\nTop 20 ä¸­ï¼Œæœ‰ {len(mod_features_in_top)} ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\")\n",
    "    \n",
    "    # --- 6. æ–°å¢åŠŸèƒ½ï¼šä¿å­˜æ¨¡å‹ ---\n",
    "    print(\"\\nä¿å­˜æ¨¡å‹åŠ Scalers...\")\n",
    "    model_path = f\"LGBM_Models_Optimized/{model_name}_best_lgbm.joblib\"\n",
    "    fscaler_path = f\"LGBM_Models_Optimized/{model_name}_feature_scaler.joblib\"\n",
    "    tscaler_path = f\"LGBM_Models_Optimized/{model_name}_target_transformer.joblib\"\n",
    "    \n",
    "    joblib.dump(best_model, model_path)\n",
    "    joblib.dump(feature_scaler, fscaler_path)\n",
    "    joblib.dump(target_transformer, tscaler_path)\n",
    "    print(f\"æ¨¡å‹å·²ä¿å­˜: {model_path}\")\n",
    "\n",
    "    # --- 7. æ–°å¢åŠŸèƒ½ï¼šç”Ÿæˆå…¨å‘¨æœŸé¢„æµ‹ ---\n",
    "    print(\"ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\")\n",
    "    X_full = data[feature_names].fillna(0) \n",
    "    \n",
    "    X_full_scaled = feature_scaler.transform(X_full)\n",
    "    Y_pred_full_transformed = best_model.predict(X_full_scaled)\n",
    "    \n",
    "    Y_pred_full_raw = target_transformer.inverse_transform(Y_pred_full_transformed.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    pred_col_name = f'LGBM_Pred_Opt_{model_name}' # ä¼˜åŒ–ç‰ˆåˆ—å\n",
    "    resid_col_name = f'LGBM_Resid_Opt_{model_name}' # ä¼˜åŒ–ç‰ˆåˆ—å\n",
    "    \n",
    "    data[pred_col_name] = Y_pred_full_raw\n",
    "    data[resid_col_name] = data[target_residual_column] - data[pred_col_name]\n",
    "    \n",
    "    stats_dict = {\n",
    "        'model': model_name,\n",
    "        'r2_score_transformed': final_r2,\n",
    "        'n_features': len(feature_names),\n",
    "        'n_mod_features': len(modulation_feature_names),\n",
    "        'top_20_mod_count': len(mod_features_in_top),\n",
    "        'best_params': opt_lgbm.best_params_,\n",
    "        'training_time': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    return data[['æ—¥æœŸ', pred_col_name, resid_col_name]], stats_dict\n",
    "\n",
    "\n",
    "# ä¸»æ‰§è¡Œ\n",
    "if __name__ == \"__main__\":\n",
    "    model_splits = {\n",
    "        'M8+2': '1996-08-01', \n",
    "        'M8+3': '1986-08-01',\n",
    "        'M0+3': '1986-09-01', \n",
    "        'M0+2': '1996-08-01'\n",
    "    }\n",
    "    \n",
    "    print(\"=== è¿è¡Œ LGBM (ç‰©ç†ç­›é€‰ä¼˜åŒ–ç‰ˆ) ===\")\n",
    "    print(\"ç­–ç•¥: åŸºç¡€å…¨é¢‘ç‡æ¢³ + (QBO+Rotation)è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\")\n",
    "    \n",
    "    try:\n",
    "        data_source_file = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\"\n",
    "        print(f\"\\nåŠ è½½æºæ•°æ®: {data_source_file}\")\n",
    "        full_data_to_save = pd.read_csv(data_source_file, parse_dates=['æ—¥æœŸ'])\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½é”™è¯¯ï¼šæ— æ³•è¯»å– {data_source_file}ã€‚é”™è¯¯: {e}\")\n",
    "        exit()\n",
    "\n",
    "    max_date_in_file = full_data_to_save['æ—¥æœŸ'].max()\n",
    "    target_date = pd.to_datetime('2050-12-31')\n",
    "    \n",
    "    if max_date_in_file < target_date:\n",
    "        print(f\"è­¦å‘Š: æºæ•°æ®æœ€å¤§æ—¥æœŸä¸º {max_date_in_file}ã€‚\")\n",
    "        print(f\"è­¦å‘Š: æ­£åœ¨æ‰©å±•æ—¥æœŸèŒƒå›´è‡³ {target_date}ã€‚\")\n",
    "        all_dates_df = pd.DataFrame({'æ—¥æœŸ': pd.date_range(\n",
    "            start=full_data_to_save['æ—¥æœŸ'].min(), \n",
    "            end=target_date, \n",
    "            freq='D'\n",
    "        )})\n",
    "        full_data_to_save = pd.merge(all_dates_df, full_data_to_save, on='æ—¥æœŸ', how='left')\n",
    "\n",
    "    results_stats_list = []\n",
    "    \n",
    "    for model_name, split_date in model_splits.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"å¤„ç†æ¨¡å‹: {model_name} (è®­ç»ƒç»“æŸäº {split_date})\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        result_df, stats_dict = run_lgbm_optimized_comb_validation(\n",
    "            data_full=full_data_to_save.copy(), \n",
    "            model_name=model_name,\n",
    "            train_start_date='1855-12-02',\n",
    "            train_end_date=split_date,\n",
    "            test_end_date='2019-11-30'\n",
    "        )\n",
    "        \n",
    "        if result_df is not None and stats_dict is not None:\n",
    "            results_stats_list.append(stats_dict)\n",
    "            full_data_to_save = pd.merge(full_data_to_save, result_df, on='æ—¥æœŸ', how='left')\n",
    "    \n",
    "    if results_stats_list:\n",
    "        output_filename = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ_Optimized.csv\" # æ–°æ–‡ä»¶å\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„ä¼˜åŒ–ç‰ˆäºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: {output_filename}\")\n",
    "        try:\n",
    "            full_data_to_save.to_csv(output_filename, index=False, float_format='%.6f')\n",
    "            print(f\"ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« {len(full_data_to_save)} è¡Œæ•°æ®ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä¿å­˜CSVå¤±è´¥: {e}\")\n",
    "        \n",
    "        results_to_print = []\n",
    "        for r in results_stats_list:\n",
    "            results_to_print.append({\n",
    "                'model': r['model'],\n",
    "                'r2_score': r['r2_score_transformed'],\n",
    "                'n_feat_total': r['n_features'],\n",
    "                'n_feat_mod': r['n_mod_features'],\n",
    "                'top_20_mod': r['top_20_mod_count'],\n",
    "                'time(s)': r['training_time']\n",
    "            })\n",
    "            \n",
    "        results_df = pd.DataFrame(results_to_print)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LGBM ç‰©ç†ç­›é€‰ä¼˜åŒ–ç‰ˆ æ€»ç»“\")\n",
    "        print(\"=\"*60)\n",
    "        print(results_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "        \n",
    "        avg_r2 = results_df['r2_score'].mean()\n",
    "        print(f\"\\nå¹³å‡RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): {avg_r2:.4f}\")\n",
    "        \n",
    "        # ä¸ä¹‹å‰çš„0.1265 (æˆ– 0.1198) æ¯”è¾ƒ\n",
    "        if avg_r2 > 0.13:\n",
    "            print(f\"âœ…âœ… å·¨å¤§æˆåŠŸ: ä¼˜åŒ–ç‰ˆRÂ² ({avg_r2:.4f}) é«˜äºåŸºçº¿ (çº¦ 0.12)ï¼\")\n",
    "        elif avg_r2 > 0.11:\n",
    "            print(f\"âœ… æˆåŠŸ: ä¼˜åŒ–ç‰ˆRÂ² ({avg_r2:.4f}) ä¸åŸºçº¿ (çº¦ 0.12) ç›¸å½“ã€‚\")\n",
    "            print(\"   è¿™è¯æ˜äº†æ¨¡å‹çš„é²æ£’æ€§ï¼Œä¸”ç‰©ç†æ„ä¹‰æ›´å¼ºã€‚\")\n",
    "        else:\n",
    "            print(f\"âŒ æ³¨æ„: ä¼˜åŒ–ç‰ˆRÂ² ({avg_r2:.4f}) ä½äºåŸºçº¿ (çº¦ 0.12)ã€‚\")\n",
    "            print(\"   è¿™å¯èƒ½æ„å‘³ç€è¢«åˆ é™¤çš„ç‰¹å¾ä¸­ä»æœ‰å¾®å¼±ä¿¡å·ã€‚\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\næ‰€æœ‰æ¨¡å‹å¤„ç†å¤±è´¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608fbb0-9aed-4354-949c-1c3d9d4c119a",
   "metadata": {},
   "source": [
    "# è¡¥å……è¡Œæ˜Ÿæ‹Ÿåˆå¯èƒ½é—æ¼çš„é•¿æœŸä¿¡æ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47796fe6-75a5-4e60-845e-ad68e065d073",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM å¯¼å…¥æˆåŠŸã€‚\n",
      "=== è¿è¡Œ LGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ: B0 + 22y, QBO, 1y, 154d, 25-30d) ===\n",
      "ç­–ç•¥: ç‰©ç†å…¨é¢‘ç‡æ¢³ + 11å¹´è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\n",
      "æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸäºŒæ¬¡æ®‹å·®\n",
      "\n",
      "åŠ è½½æºæ•°æ®: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M8+2 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (å˜åŒ–ç‡) ç‰¹å¾...\n",
      "æ€»ç‰¹å¾æ•°: 62 (å…¨é¢‘ç‡æ¢³ + å˜åŒ–ç‡)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0105\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 1.0, 'learning_rate': 0.016395645320842304, 'n_estimators': 100, 'num_leaves': 14, 'reg_alpha': 3.6710523504410557, 'reg_lambda': 0.1, 'subsample': 1.0})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin        317\n",
      "Hale_22y_cos            233\n",
      "Hale_22y_sin            162\n",
      "Mod_Hale_22y_cos        154\n",
      "Mod_QBO_2.7y_cos        105\n",
      "Mod_QBO_2.7y_sin         42\n",
      "Mod_QBO_2.2y_sin         40\n",
      "QBO_2.7y_cos             29\n",
      "Mod_Annual_370d_cos      29\n",
      "Mod_QBO_2.2y_cos         24\n",
      "Mod_Annual_365d_sin      19\n",
      "Mod_QBO_1.7y_cos         17\n",
      "Mod_B0_sq                16\n",
      "Mod_Annual_360d_sin      15\n",
      "QBO_1.7y_sin             14\n",
      "QBO_2.7y_sin             11\n",
      "Mod_QBO_1.7y_sin          8\n",
      "Mod_Rotation_27d_sin      8\n",
      "Mod_Rotation_28d_cos      8\n",
      "QBO_2.2y_cos              8\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 14 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M8+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+3 (è®­ç»ƒç»“æŸäº 1986-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M8+3 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (å˜åŒ–ç‡) ç‰¹å¾...\n",
      "æ€»ç‰¹å¾æ•°: 62 (å…¨é¢‘ç‡æ¢³ + å˜åŒ–ç‡)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47725, æµ‹è¯•12174\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.1170\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 1.0, 'learning_rate': 0.009976053533419084, 'n_estimators': 252, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 20.0, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin        315\n",
      "Mod_Hale_22y_cos        190\n",
      "Hale_22y_cos            156\n",
      "Hale_22y_sin            139\n",
      "Mod_QBO_2.7y_cos         72\n",
      "Mod_QBO_2.7y_sin         20\n",
      "Mod_Annual_360d_cos      20\n",
      "Mod_Annual_370d_cos      19\n",
      "Mod_Rotation_28d_cos     10\n",
      "Mod_Annual_360d_sin       9\n",
      "Mod_Rotation_27d_sin      9\n",
      "Mod_Annual_365d_cos       9\n",
      "Mod_B0_sq                 9\n",
      "Annual_370d_cos           6\n",
      "Mod_B0                    6\n",
      "Annual_370d_sin           6\n",
      "Mod_QBO_2.2y_cos          5\n",
      "Mod_Rieger_154d_cos       2\n",
      "Mod_QBO_1.7y_cos          2\n",
      "Mod_Annual_365d_sin       1\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 16 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M8+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+3 (è®­ç»ƒç»“æŸäº 1986-09-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M0+3 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (å˜åŒ–ç‡) ç‰¹å¾...\n",
      "æ€»ç‰¹å¾æ•°: 62 (å…¨é¢‘ç‡æ¢³ + å˜åŒ–ç‡)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47756, æµ‹è¯•12143\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0879\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.003672208348107611, 'n_estimators': 579, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 1.0})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_cos             653\n",
      "Mod_Hale_22y_sin             607\n",
      "Hale_22y_cos                 352\n",
      "Mod_QBO_2.7y_cos             126\n",
      "Hale_22y_sin                  80\n",
      "Planetary_Scaled_Diff         75\n",
      "Mod_B0_sq                     65\n",
      "QBO_2.7y_sin                  60\n",
      "Mod_QBO_2.7y_sin              58\n",
      "Mod_QBO_1.7y_cos              49\n",
      "Mod_Planetary_Scaled_Diff     48\n",
      "Mod_QBO_2.2y_sin              34\n",
      "Mod_QBO_2.2y_cos              25\n",
      "Mod_QBO_1.7y_sin              21\n",
      "Mod_B0                        13\n",
      "Mod_Annual_365d_cos           12\n",
      "QBO_2.7y_cos                  10\n",
      "Mod_Annual_370d_cos            9\n",
      "Mod_Annual_360d_sin            8\n",
      "Mod_Annual_365d_sin            7\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 15 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M0+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M0+2 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (å˜åŒ–ç‡) ç‰¹å¾...\n",
      "æ€»ç‰¹å¾æ•°: 62 (å…¨é¢‘ç‡æ¢³ + å˜åŒ–ç‡)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0413\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.020841367036498474, 'n_estimators': 161, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 20.0, 'subsample': 1.0})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin             161\n",
      "Mod_Hale_22y_cos             107\n",
      "Planetary_Scaled_Diff         80\n",
      "Hale_22y_cos                  61\n",
      "Mod_Planetary_Scaled_Diff     56\n",
      "Mod_QBO_2.7y_cos              44\n",
      "Mod_B0_sq                     21\n",
      "Mod_QBO_2.2y_cos              19\n",
      "Mod_Annual_360d_sin           16\n",
      "Mod_QBO_2.7y_sin              14\n",
      "Mod_QBO_1.7y_cos              14\n",
      "Mod_Annual_370d_cos           11\n",
      "Mod_QBO_2.2y_sin               9\n",
      "Mod_Annual_370d_sin            7\n",
      "Mod_B0                         6\n",
      "Mod_Annual_360d_cos            5\n",
      "QBO_1.7y_sin                   3\n",
      "Mod_QBO_1.7y_sin               2\n",
      "Hale_22y_sin                   2\n",
      "Mod_Annual_365d_sin            2\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 16 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M0+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "============================================================\n",
      "ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„äºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ.csv\n",
      "ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« 73780 è¡Œæ•°æ®ã€‚\n",
      "\n",
      "============================================================\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ æ€»ç»“\n",
      "============================================================\n",
      "model  r2_score  n_features  top_20_mod  time(s)\n",
      " M8+2    0.0105          62          14 449.8551\n",
      " M8+3    0.1170          62          16 369.4227\n",
      " M0+3    0.0879          62          15 369.8375\n",
      " M0+2    0.0413          62          16 346.7903\n",
      "\n",
      "å¹³å‡RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): 0.0642\n",
      "âœ…âœ…âœ… å·¨å¤§æˆåŠŸ: æ‰€æœ‰ 4 ä¸ªæ¨¡å‹ RÂ² å‡ä¸ºæ­£å€¼ï¼\n",
      "ğŸ’¡ æ´å¯Ÿ: è°ƒåˆ¶ç‰¹å¾ (Mod_) åœ¨æ¨¡å‹ä¸­å æœ‰é‡è¦åœ°ä½ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os  # æ–°å¢ï¼šç”¨äºåˆ›å»ºç›®å½•\n",
    "import joblib  # æ–°å¢ï¼šç”¨äºä¿å­˜æ¨¡å‹\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# å¯¼å…¥ QuantileTransformer (å…³é”®ä¿®å¤)\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# --- æ ¸å¿ƒï¼šéçº¿æ€§æ¨¡å‹å¯¼å…¥ ---\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM å¯¼å…¥æˆåŠŸã€‚\")\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯ï¼šæœªæ‰¾åˆ° lightgbm åº“ã€‚\")\n",
    "    print(\"è¯·å®‰è£…: pip install lightgbm\")\n",
    "    exit()\n",
    "\n",
    "# å¤©æ–‡å­¦åº“å¯¼å…¥\n",
    "try:\n",
    "    from astropy.time import Time\n",
    "    import astropy.units as u\n",
    "    from sunpy.coordinates import sun\n",
    "except ImportError:\n",
    "    print(\"ç¼ºå°‘å¤©æ–‡å­¦åº“\")\n",
    "    exit()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_lgbm_full_comb_validation(\n",
    "    data_full, model_name, train_start_date, train_end_date, test_end_date\n",
    "):\n",
    "    \"\"\"\n",
    "    è¿è¡Œ LGBM (æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ)\n",
    "    - ç‰¹å¾: B0 + æ‰€æœ‰è‘—åå‘¨æœŸ (22y, QBO, 1y, 154d, 25-30d)\n",
    "    - è°ƒåˆ¶: 11å¹´è¡Œæ˜Ÿæ‹Ÿåˆ\n",
    "    - Yå˜æ¢: QuantileTransformer\n",
    "    - è°ƒä¼˜: å¼ºæ­£åˆ™åŒ–\n",
    "    - æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸé¢„æµ‹\n",
    "    \"\"\"\n",
    "    \n",
    "    # ä½¿ç”¨ä¼ å…¥çš„å®Œæ•´æ•°æ®\n",
    "    data = data_full.copy() \n",
    "    \n",
    "    target_residual_column = f'æ®‹å·®_{model_name}'\n",
    "    planetary_fit_column = f'æ‹ŸåˆSSN_{model_name}'\n",
    "    \n",
    "    # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨\n",
    "    os.makedirs(\"LGBM_Models\", exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: {model_name} ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨\n",
    "    if target_residual_column not in data.columns or planetary_fit_column not in data.columns:\n",
    "        print(f\"é”™è¯¯: ç¼ºå°‘åˆ— {target_residual_column} æˆ– {planetary_fit_column}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 1. ç‰¹å¾å·¥ç¨‹ï¼šB0 + å…¨é¢‘ç‡æ¢³ (åœ¨æ‰€æœ‰æ—¥æœŸä¸Š) ---\n",
    "    print(\"1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    times_astropy = Time(data['æ—¥æœŸ'].values)\n",
    "    \n",
    "    original_feature_names = []\n",
    "    \n",
    "    # B0 (æ—¥é¢ä¸­å¿ƒçº¬åº¦) - çœŸå®å¹´åº¦æŒ¯å¹…\n",
    "    b0_deg = sun.B0(times_astropy).deg\n",
    "    data['B0'] = b0_deg\n",
    "    data['B0_sq'] = b0_deg ** 2\n",
    "    original_feature_names.extend(['B0', 'B0_sq'])\n",
    "    \n",
    "    # åŸºäºæ—¶é—´çš„å›ºå®šé¢‘ç‡ç‰¹å¾\n",
    "    days_since_start = (data['æ—¥æœŸ'] - data['æ—¥æœŸ'].min()).dt.days\n",
    "    \n",
    "    # === å®šä¹‰æˆ‘ä»¬çš„é¢‘ç‡æ¢³ ===\n",
    "    \n",
    "    # 1. Hale (22y)\n",
    "    hale_rad = 2 * np.pi * days_since_start / (22.0 * 365.25)\n",
    "    data['Hale_22y_sin'] = np.sin(hale_rad)\n",
    "    data['Hale_22y_cos'] = np.cos(hale_rad)\n",
    "    original_feature_names.extend(['Hale_22y_sin', 'Hale_22y_cos'])\n",
    "\n",
    "    # 2. QBO (1.5y - 3y)\n",
    "    qbo_periods = [1.7, 2.2, 2.7] # å¹´\n",
    "    for p in qbo_periods:\n",
    "        rad = 2 * np.pi * days_since_start / (p * 365.25)\n",
    "        name = f'QBO_{p:.1f}y'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 3. Annual (1y)\n",
    "    annual_periods = [360, 365.25, 370] # å¤©\n",
    "    for p in annual_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Annual_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 4. Rieger (154d)\n",
    "    rieger_rad = 2 * np.pi * days_since_start / 154\n",
    "    data['Rieger_154d_sin'] = np.sin(rieger_rad)\n",
    "    data['Rieger_154d_cos'] = np.cos(rieger_rad)\n",
    "    original_feature_names.extend(['Rieger_154d_sin', 'Rieger_154d_cos'])\n",
    "\n",
    "    # 5. Rotation (25d-30d)\n",
    "    rotation_periods = [25, 26, 27, 28, 29, 30] # å¤©\n",
    "    for p in rotation_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Rotation_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "    \n",
    "    \n",
    "    # --- 2. è°ƒåˆ¶ç‰¹å¾å·¥ç¨‹ (é‡æ„) ---\n",
    "    # ç›®æ ‡ï¼šåœ¨è®­ç»ƒé›†ä¸Š fit Scalerï¼Œåœ¨å…¨å‘¨æœŸä¸Š transform\n",
    "    print(\"2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    \n",
    "    # a. åˆ›å»ºç”¨äºæ‹Ÿåˆ Scaler çš„è®­ç»ƒæ©ç \n",
    "    # è®­ç»ƒé›†æ©ç ï¼ˆä»…ç”¨äºæ‹Ÿåˆ Scaler å’Œæ¨¡å‹ï¼‰\n",
    "    train_mask_dates = (data['æ—¥æœŸ'] >= train_start_date) & (data['æ—¥æœŸ'] <= train_end_date)\n",
    "    # å¿…é¡»æ˜¯å¹²å‡€çš„ã€éNaNçš„æ•°æ®\n",
    "    train_mask_clean = train_mask_dates & data[target_residual_column].notna() & data[planetary_fit_column].notna()\n",
    "    \n",
    "    if train_mask_clean.sum() == 0:\n",
    "        print(f\"é”™è¯¯ï¼šåœ¨ {train_start_date} å’Œ {train_end_date} ä¹‹é—´æ²¡æœ‰å¹²å‡€çš„è®­ç»ƒæ•°æ®ã€‚\")\n",
    "        return None, None\n",
    "        \n",
    "    # b. Fit è°ƒåˆ¶å™¨ (11å¹´å‘¨æœŸä¿¡å·) Scaler (ä»…åœ¨è®­ç»ƒæ•°æ®ä¸Š)\n",
    "    planetary_fit_values_train = data.loc[train_mask_clean, [planetary_fit_column]]\n",
    "    scaler_fit = StandardScaler()\n",
    "    scaler_fit.fit(planetary_fit_values_train)\n",
    "    \n",
    "    # c. Transform (å…¨å‘¨æœŸ)\n",
    "    # è­¦å‘Šï¼šå¦‚æœ planetary_fit_column åœ¨æœªæ¥æ˜¯ NaNï¼Œè¿™é‡Œä¼šäº§ç”Ÿ NaN\n",
    "    planetary_fit_values_full = data[[planetary_fit_column]].fillna(0) # å‡è®¾æœªæ¥æ‹Ÿåˆä¸º0ï¼ˆå¦‚æœä¸¢å¤±ï¼‰ï¼Œè¿™ä¸ç†æƒ³ä½†èƒ½é˜²æ­¢å´©æºƒ\n",
    "    data['Planetary_Scaled'] = scaler_fit.transform(planetary_fit_values_full).flatten()\n",
    "\n",
    "    # --- [ *** æ–°å¢ä»£ç  *** ] ---\n",
    "    # 2.c.1: åˆ›å»ºå˜åŒ–ç‡ç‰¹å¾ (1é˜¶å·®åˆ†)\n",
    "    # è¿™ä»£è¡¨äº†11å¹´å‘¨æœŸçš„â€œä¸Šå‡ç›¸â€ï¼ˆæ­£å€¼ï¼‰æˆ–â€œä¸‹é™ç›¸â€ï¼ˆè´Ÿå€¼ï¼‰\n",
    "    print(\"... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (å˜åŒ–ç‡) ç‰¹å¾...\")\n",
    "    data['Planetary_Scaled_Diff'] = data['Planetary_Scaled'].diff(1).fillna(0)\n",
    "    \n",
    "    # 2.c.2: å°†å…¶æ·»åŠ åˆ° *åŸºç¡€* ç‰¹å¾åˆ—è¡¨\n",
    "    # å…³é”®ï¼šè¿™æ ·å®ƒåœ¨ä¸‹ä¸€æ­¥ä¸­ä¼šè‡ªåŠ¨è·å¾—è‡ªå·±çš„ \"Mod_\" ç‰ˆæœ¬\n",
    "    original_feature_names.append('Planetary_Scaled_Diff')\n",
    "    # --- [ *** æ–°å¢ä»£ç ç»“æŸ *** ] ---\n",
    "    \n",
    "    # d. åˆ›å»ºè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)\n",
    "    modulation_feature_names = []\n",
    "    for feature in original_feature_names:\n",
    "        new_feature_name = f'Mod_{feature}'\n",
    "        data.loc[:, new_feature_name] = data['Planetary_Scaled'] * data[feature]\n",
    "        modulation_feature_names.append(new_feature_name)\n",
    "    \n",
    "    feature_names = original_feature_names + modulation_feature_names\n",
    "    print(f\"æ€»ç‰¹å¾æ•°: {len(feature_names)} (å…¨é¢‘ç‡æ¢³ + å˜åŒ–ç‡)\")\n",
    "    \n",
    "    # --- 3. æ•°æ®åˆ†å‰²ä¸å˜æ¢ (ç”¨äºè®­ç»ƒ) ---\n",
    "    \n",
    "    # ä»…ä½¿ç”¨å…·æœ‰æœ‰æ•ˆæ®‹å·®çš„è¡Œè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•\n",
    "    data_clean = data.dropna(subset=[target_residual_column] + feature_names)\n",
    "    \n",
    "    X = data_clean[feature_names]\n",
    "    Y_raw = data_clean[target_residual_column] # Y åŸå§‹å€¼\n",
    "    groups = data_clean['æ—¥æœŸ'].dt.year\n",
    "    dates = data_clean['æ—¥æœŸ']\n",
    "    \n",
    "    train_mask = (dates >= train_start_date) & (dates <= train_end_date)\n",
    "    test_start_date_dt = pd.to_datetime(train_end_date) + pd.Timedelta(days=1)\n",
    "    test_mask = (dates >= test_start_date_dt) & (dates <= test_end_date)\n",
    "    \n",
    "    X_train_raw = X[train_mask]\n",
    "    Y_train_raw = Y_raw[train_mask]\n",
    "    X_test_raw = X[test_mask]\n",
    "    Y_test_raw = Y_raw[test_mask]\n",
    "    groups_train = groups[train_mask]\n",
    "    \n",
    "    if len(X_train_raw) == 0 or len(X_test_raw) == 0:\n",
    "        print(\"é”™è¯¯ï¼šè®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º\")\n",
    "        return None, None\n",
    "\n",
    "    # a. Fit X å˜æ¢ (StandardScaler)\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_train = feature_scaler.fit_transform(X_train_raw)\n",
    "    X_test = feature_scaler.transform(X_test_raw)\n",
    "\n",
    "    # b. Fit Y å˜æ¢ (QuantileTransformer) - å…³é”®ä¿®å¤\n",
    "    print(\"åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\")\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "    Y_train = target_transformer.fit_transform(Y_train_raw.values.reshape(-1, 1)).flatten()\n",
    "    Y_test = target_transformer.transform(Y_test_raw.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(f\"æ•°æ®: è®­ç»ƒ{len(X_train)}, æµ‹è¯•{len(X_test)}\")\n",
    "    \n",
    "    # --- 4. è´å¶æ–¯ä¼˜åŒ– - LGBM (å¼ºæ­£åˆ™åŒ–) ---\n",
    "    n_splits = max(2, min(5, groups_train.nunique()))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    search_spaces = {\n",
    "        'n_estimators': Integer(100, 800),\n",
    "        'num_leaves': Integer(5, 30),\n",
    "        'learning_rate': Real(1e-3, 0.1, 'log-uniform'),\n",
    "        'reg_alpha': Real(0.1, 20.0, 'log-uniform'), \n",
    "        'reg_lambda': Real(0.1, 20.0, 'log-uniform'),\n",
    "        'subsample': Real(0.7, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.7, 1.0, 'uniform')\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        random_state=42, \n",
    "        n_jobs=1, \n",
    "        objective='regression_l1',\n",
    "        force_row_wise=True, # å¼ºåˆ¶ä½¿ç”¨è¡Œä¼˜å…ˆï¼Œæ¶ˆé™¤è‡ªåŠ¨æ£€æµ‹çš„æç¤º\n",
    "        verbose=-1           # æŠ‘åˆ¶æ‰€æœ‰ LightGBM çš„å†…éƒ¨è¾“å‡ºï¼ˆæ¨èï¼‰\n",
    "    )\n",
    "\n",
    "    opt_lgbm = BayesSearchCV(\n",
    "        lgb_model, \n",
    "        search_spaces, \n",
    "        n_iter=100, # <-- ä» 30 å¢åŠ åˆ° 50 \n",
    "        cv=gkf, \n",
    "        n_jobs=-2,\n",
    "        random_state=42, \n",
    "        scoring='r2'\n",
    "    )\n",
    "    \n",
    "    print(\"è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\")\n",
    "    opt_lgbm.fit(X_train, Y_train, groups=groups_train)\n",
    "    \n",
    "    # --- 5. ç»“æœåˆ†æ ---\n",
    "    best_model = opt_lgbm.best_estimator_\n",
    "    Y_pred_test = best_model.predict(X_test)\n",
    "    final_r2 = r2_score(Y_test, Y_pred_test) \n",
    "    \n",
    "    print(f\"\\nLGBM å…¨é¢‘ç‡æ¢³ç‰ˆ RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): {final_r2:.4f}\")\n",
    "    if final_r2 > 0:\n",
    "        print(\"âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\")\n",
    "        \n",
    "    print(f\"æœ€ä½³å‚æ•°: {opt_lgbm.best_params_}\")\n",
    "    \n",
    "    # ç‰¹å¾é‡è¦æ€§\n",
    "    importances = pd.Series(best_model.feature_importances_, index=feature_names)\n",
    "    print(\"\\nç‰¹å¾é‡è¦æ€§ (Top 20):\")\n",
    "    top_features = importances.sort_values(ascending=False).head(20) \n",
    "    print(top_features.to_string())\n",
    "    \n",
    "    mod_features_in_top = [f for f in top_features.index if f.startswith('Mod_')]\n",
    "    print(f\"\\nTop 20 ä¸­ï¼Œæœ‰ {len(mod_features_in_top)} ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\")\n",
    "    \n",
    "    # --- 6. æ–°å¢åŠŸèƒ½ï¼šä¿å­˜æ¨¡å‹ ---\n",
    "    print(\"\\nä¿å­˜æ¨¡å‹åŠ Scalers...\")\n",
    "    model_path = f\"LGBM_Models/{model_name}_best_lgbm.joblib\"\n",
    "    fscaler_path = f\"LGBM_Models/{model_name}_feature_scaler.joblib\"\n",
    "    tscaler_path = f\"LGBM_Models/{model_name}_target_transformer.joblib\"\n",
    "    \n",
    "    joblib.dump(best_model, model_path)\n",
    "    joblib.dump(feature_scaler, fscaler_path)\n",
    "    joblib.dump(target_transformer, tscaler_path)\n",
    "    print(f\"æ¨¡å‹å·²ä¿å­˜: {model_path}\")\n",
    "\n",
    "    # --- 7. æ–°å¢åŠŸèƒ½ï¼šç”Ÿæˆå…¨å‘¨æœŸé¢„æµ‹ ---\n",
    "    print(\"ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\")\n",
    "    \n",
    "    # å‡†å¤‡å…¨å‘¨æœŸçš„ X ç‰¹å¾\n",
    "    # å¿…é¡»å¡«å……ç‰¹å¾ä¸­çš„NaNï¼ˆä¾‹å¦‚ï¼Œå¦‚æœ Planetary_Scaled æœ€ç»ˆä¸ºNaNï¼‰\n",
    "    X_full = data[feature_names].fillna(0) \n",
    "    \n",
    "    X_full_scaled = feature_scaler.transform(X_full)\n",
    "    Y_pred_full_transformed = best_model.predict(X_full_scaled)\n",
    "    \n",
    "    # åå˜æ¢å›åŸå§‹å°ºåº¦\n",
    "    Y_pred_full_raw = target_transformer.inverse_transform(Y_pred_full_transformed.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # åˆ›å»ºé¢„æµ‹åˆ—å’ŒäºŒæ¬¡æ®‹å·®åˆ—\n",
    "    pred_col_name = f'LGBM_Pred_{model_name}'\n",
    "    resid_col_name = f'LGBM_Resid_{model_name}'\n",
    "    \n",
    "    data[pred_col_name] = Y_pred_full_raw\n",
    "    # åŸå§‹æ®‹å·® - LGBMé¢„æµ‹çš„æ®‹å·® = äºŒæ¬¡æ®‹å·®\n",
    "    data[resid_col_name] = data[target_residual_column] - data[pred_col_name]\n",
    "    \n",
    "    # å‡†å¤‡ç»Ÿè®¡å­—å…¸\n",
    "    stats_dict = {\n",
    "        'model': model_name,\n",
    "        'r2_score_transformed': final_r2,\n",
    "        'n_features': len(feature_names),\n",
    "        'top_20_mod_count': len(mod_features_in_top),\n",
    "        'best_params': opt_lgbm.best_params_,\n",
    "        'training_time': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    # è¿”å›åŒ…å«æ–°åˆ—çš„DataFrameï¼ˆä»…å«å¿…è¦åˆ—ï¼‰å’Œç»Ÿè®¡ç»“æœ\n",
    "    return data[['æ—¥æœŸ', pred_col_name, resid_col_name]], stats_dict\n",
    "\n",
    "\n",
    "# ä¸»æ‰§è¡Œ - è¿è¡Œ LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ\n",
    "if __name__ == \"__main__\":\n",
    "    model_splits = {\n",
    "        'M8+2': '1996-08-01', \n",
    "        'M8+3': '1986-08-01',\n",
    "        'M0+3': '1986-09-01', \n",
    "        'M0+2': '1996-08-01'\n",
    "    }\n",
    "    \n",
    "    print(\"=== è¿è¡Œ LGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ: B0 + 22y, QBO, 1y, 154d, 25-30d) ===\")\n",
    "    print(\"ç­–ç•¥: ç‰©ç†å…¨é¢‘ç‡æ¢³ + 11å¹´è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\")\n",
    "    print(\"æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸäºŒæ¬¡æ®‹å·®\")\n",
    "    \n",
    "    # --- æ–°å¢ï¼šåœ¨å¾ªç¯å¤–åŠ è½½å’Œå‡†å¤‡æ•°æ® ---\n",
    "    try:\n",
    "        data_source_file = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\"\n",
    "        print(f\"\\nåŠ è½½æºæ•°æ®: {data_source_file}\")\n",
    "        full_data_to_save = pd.read_csv(data_source_file, parse_dates=['æ—¥æœŸ'])\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½é”™è¯¯ï¼šæ— æ³•è¯»å– {data_source_file}ã€‚é”™è¯¯: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # æ£€æŸ¥å¹¶æ‰©å±•æ—¥æœŸè‡³2050å¹´\n",
    "    max_date_in_file = full_data_to_save['æ—¥æœŸ'].max()\n",
    "    target_date = pd.to_datetime('2050-12-31')\n",
    "    \n",
    "    if max_date_in_file < target_date:\n",
    "        print(f\"è­¦å‘Š: æºæ•°æ®æœ€å¤§æ—¥æœŸä¸º {max_date_in_file}ã€‚\")\n",
    "        print(f\"è­¦å‘Š: æ­£åœ¨æ‰©å±•æ—¥æœŸèŒƒå›´è‡³ {target_date}ã€‚\")\n",
    "        print(\"è­¦å‘Š: è¯·ç¡®ä¿ 'æ‹ŸåˆSSN' (è¡Œæ˜Ÿæ‹Ÿåˆ) åˆ—åœ¨æºæ–‡ä»¶ä¸­å·²å¤–æ¨è‡³2050å¹´ï¼Œå¦åˆ™é¢„æµ‹å°†ä¸å‡†ç¡®ï¼\")\n",
    "        \n",
    "        all_dates_df = pd.DataFrame({'æ—¥æœŸ': pd.date_range(\n",
    "            start=full_data_to_save['æ—¥æœŸ'].min(), \n",
    "            end=target_date, \n",
    "            freq='D'\n",
    "        )})\n",
    "        full_data_to_save = pd.merge(all_dates_df, full_data_to_save, on='æ—¥æœŸ', how='left')\n",
    "\n",
    "    # ç”¨äºä¿å­˜ç»Ÿè®¡ç»“æœ\n",
    "    results_stats_list = []\n",
    "    \n",
    "    # å¾ªç¯å¤„ç†æ¯ä¸ªæ¨¡å‹\n",
    "    for model_name, split_date in model_splits.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"å¤„ç†æ¨¡å‹: {model_name} (è®­ç»ƒç»“æŸäº {split_date})\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ä¼ å…¥å®Œæ•´æ•°æ®\n",
    "        result_df, stats_dict = run_lgbm_full_comb_validation(\n",
    "            data_full=full_data_to_save.copy(), # ä¼ å…¥æ•°æ®çš„å‰¯æœ¬\n",
    "            model_name=model_name,\n",
    "            train_start_date='1855-12-02',\n",
    "            train_end_date=split_date,\n",
    "            test_end_date='2019-11-30'\n",
    "        )\n",
    "        \n",
    "        if result_df is not None and stats_dict is not None:\n",
    "            results_stats_list.append(stats_dict)\n",
    "            # å°†è¯¥æ¨¡å‹çš„ç»“æœåˆå¹¶å›ä¸»DataFrame\n",
    "            full_data_to_save = pd.merge(full_data_to_save, result_df, on='æ—¥æœŸ', how='left')\n",
    "    \n",
    "    # --- æ–°å¢ï¼šä¿å­˜åŒ…å«æ‰€æœ‰ç»“æœçš„CSV ---\n",
    "    if results_stats_list:\n",
    "        output_filename = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ.csv\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„äºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: {output_filename}\")\n",
    "        try:\n",
    "            full_data_to_save.to_csv(output_filename, index=False, float_format='%.6f')\n",
    "            print(f\"ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« {len(full_data_to_save)} è¡Œæ•°æ®ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä¿å­˜CSVå¤±è´¥: {e}\")\n",
    "        \n",
    "        # --- æ‰“å°æ€»ç»“æŠ¥å‘Š (ä½¿ç”¨ç»Ÿè®¡æ•°æ®) ---\n",
    "        results_to_print = []\n",
    "        for r in results_stats_list:\n",
    "            results_to_print.append({\n",
    "                'model': r['model'],\n",
    "                'r2_score': r['r2_score_transformed'],\n",
    "                'n_features': r['n_features'],\n",
    "                'top_20_mod': r['top_20_mod_count'],\n",
    "                'time(s)': r['training_time']\n",
    "            })\n",
    "            \n",
    "        results_df = pd.DataFrame(results_to_print)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ æ€»ç»“\")\n",
    "        print(\"=\"*60)\n",
    "        print(results_df.to_string(index=False, float_format=\"%.4f\"))\n",
    "        \n",
    "        avg_r2 = results_df['r2_score'].mean()\n",
    "        print(f\"\\nå¹³å‡RÂ² (åœ¨å˜æ¢åçš„Yä¸Š): {avg_r2:.4f}\")\n",
    "        \n",
    "        positive_r2 = results_df[results_df['r2_score'] > 0]\n",
    "        if len(positive_r2) == 4:\n",
    "            print(\"âœ…âœ…âœ… å·¨å¤§æˆåŠŸ: æ‰€æœ‰ 4 ä¸ªæ¨¡å‹ RÂ² å‡ä¸ºæ­£å€¼ï¼\")\n",
    "        elif len(positive_r2) > 0:\n",
    "            print(f\"âœ… æˆåŠŸ: {len(positive_r2)} ä¸ªæ¨¡å‹è·å¾—æ­£RÂ²ã€‚\")\n",
    "        else:\n",
    "            print(\"âŒ å¤±è´¥: æ‰€æœ‰æ¨¡å‹RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\")\n",
    "        \n",
    "        if results_df['top_20_mod'].mean() >= 10: \n",
    "             print(\"ğŸ’¡ æ´å¯Ÿ: è°ƒåˆ¶ç‰¹å¾ (Mod_) åœ¨æ¨¡å‹ä¸­å æœ‰é‡è¦åœ°ä½ã€‚\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\næ‰€æœ‰æ¨¡å‹å¤„ç†å¤±è´¥\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86716369-40f0-4ee3-9e1f-bb436f984abb",
   "metadata": {},
   "source": [
    "# åœ¨11å˜åŒ–ç‡çš„åŸºç¡€ä¸Šï¼Œå¢åŠ â€œåŠ é€Ÿåº¦â€ã€‚æœ€ä¼˜ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c96222-8020-4e3a-9743-33721bbe6894",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM å¯¼å…¥æˆåŠŸã€‚\n",
      "=== è¿è¡Œ LGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ: B0 + 22y, QBO, 1y, 154d, 25-30d) ===\n",
      "ç­–ç•¥: ç‰©ç†å…¨é¢‘ç‡æ¢³ + 11å¹´è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\n",
      "æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸäºŒæ¬¡æ®‹å·®\n",
      "\n",
      "åŠ è½½æºæ•°æ®: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M8+2 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (é€Ÿåº¦) ç‰¹å¾...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Accel' (åŠ é€Ÿåº¦) ç‰¹å¾...\n",
      "åŸºç¡€ç‰¹å¾æ•°é‡ (åŒ…æ‹¬ Diff å’Œ Accel): 32\n",
      "æ€»ç‰¹å¾æ•°: 64 (å…¨é¢‘ç‡æ¢³ + é€Ÿåº¦ + åŠ é€Ÿåº¦)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM æœ€ä½³ CV RÂ² (M_CV_R2): 0.0629\n",
      "LGBM æ£€éªŒé›† Test RÂ² (M_T_R2): 0.0108\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 1.0, 'learning_rate': 0.0021322706054339017, 'n_estimators': 675, 'num_leaves': 14, 'reg_alpha': 0.1, 'reg_lambda': 20.0, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin        2179\n",
      "Hale_22y_cos            1587\n",
      "Mod_Hale_22y_cos        1093\n",
      "Hale_22y_sin            1016\n",
      "Mod_QBO_2.7y_cos         774\n",
      "Mod_QBO_2.2y_sin         294\n",
      "Mod_QBO_2.7y_sin         259\n",
      "QBO_2.7y_cos             178\n",
      "Mod_Annual_370d_cos      173\n",
      "Mod_Annual_365d_sin      149\n",
      "Mod_B0_sq                146\n",
      "Mod_QBO_2.2y_cos         138\n",
      "Mod_QBO_1.7y_cos          92\n",
      "QBO_1.7y_sin              81\n",
      "QBO_2.2y_cos              70\n",
      "Mod_Annual_360d_cos       68\n",
      "Mod_Annual_360d_sin       67\n",
      "Mod_QBO_1.7y_sin          63\n",
      "Mod_Rotation_28d_cos      53\n",
      "Mod_Rotation_27d_sin      46\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 15 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M8+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M8+3 (è®­ç»ƒç»“æŸäº 1986-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M8+3 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (é€Ÿåº¦) ç‰¹å¾...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Accel' (åŠ é€Ÿåº¦) ç‰¹å¾...\n",
      "åŸºç¡€ç‰¹å¾æ•°é‡ (åŒ…æ‹¬ Diff å’Œ Accel): 32\n",
      "æ€»ç‰¹å¾æ•°: 64 (å…¨é¢‘ç‡æ¢³ + é€Ÿåº¦ + åŠ é€Ÿåº¦)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47725, æµ‹è¯•12174\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM æœ€ä½³ CV RÂ² (M_CV_R2): 0.0301\n",
      "LGBM æ£€éªŒé›† Test RÂ² (M_T_R2): 0.1216\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.002902903093823585, 'n_estimators': 800, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 2.317826044224675, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin        921\n",
      "Mod_Hale_22y_cos        558\n",
      "Hale_22y_cos            508\n",
      "Hale_22y_sin            445\n",
      "Mod_QBO_2.7y_cos        309\n",
      "Mod_QBO_2.7y_sin         97\n",
      "Mod_QBO_2.2y_cos         63\n",
      "Mod_B0_sq                62\n",
      "Mod_Annual_360d_cos      50\n",
      "Mod_QBO_2.2y_sin         36\n",
      "Mod_B0                   25\n",
      "Mod_QBO_1.7y_cos         24\n",
      "Mod_Annual_370d_cos      21\n",
      "Mod_Rotation_28d_cos     19\n",
      "Mod_Annual_360d_sin      13\n",
      "Mod_Rotation_27d_sin     10\n",
      "Mod_Annual_365d_cos       9\n",
      "Mod_QBO_1.7y_sin          7\n",
      "Mod_Rieger_154d_sin       6\n",
      "Annual_370d_cos           5\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 17 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M8+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+3 (è®­ç»ƒç»“æŸäº 1986-09-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M0+3 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (é€Ÿåº¦) ç‰¹å¾...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Accel' (åŠ é€Ÿåº¦) ç‰¹å¾...\n",
      "åŸºç¡€ç‰¹å¾æ•°é‡ (åŒ…æ‹¬ Diff å’Œ Accel): 32\n",
      "æ€»ç‰¹å¾æ•°: 64 (å…¨é¢‘ç‡æ¢³ + é€Ÿåº¦ + åŠ é€Ÿåº¦)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ47756, æµ‹è¯•12143\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM æœ€ä½³ CV RÂ² (M_CV_R2): 0.0381\n",
      "LGBM æ£€éªŒé›† Test RÂ² (M_T_R2): 0.0968\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.011271387782685329, 'n_estimators': 193, 'num_leaves': 5, 'reg_alpha': 1.5078725843772192, 'reg_lambda': 0.1, 'subsample': 1.0})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_cos             188\n",
      "Mod_Hale_22y_sin             172\n",
      "Hale_22y_cos                  98\n",
      "Planetary_Scaled_Accel        56\n",
      "Mod_QBO_2.7y_cos              43\n",
      "Mod_B0_sq                     31\n",
      "Planetary_Scaled_Diff         30\n",
      "Mod_QBO_1.7y_cos              26\n",
      "Mod_QBO_2.2y_sin              23\n",
      "Mod_QBO_2.7y_sin              20\n",
      "Hale_22y_sin                  20\n",
      "QBO_2.7y_sin                  17\n",
      "Mod_Planetary_Scaled_Diff     13\n",
      "Mod_Annual_365d_cos            9\n",
      "Mod_QBO_1.7y_sin               6\n",
      "Mod_Annual_370d_cos            4\n",
      "Mod_QBO_2.2y_cos               4\n",
      "Mod_Annual_365d_sin            4\n",
      "Mod_B0                         2\n",
      "Mod_Annual_360d_sin            2\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 15 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M0+3_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "==================================================\n",
      "å¤„ç†æ¨¡å‹: M0+2 (è®­ç»ƒç»“æŸäº 1996-08-01)\n",
      "==================================================\n",
      "\n",
      "=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: M0+2 ===\n",
      "1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (é€Ÿåº¦) ç‰¹å¾...\n",
      "... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Accel' (åŠ é€Ÿåº¦) ç‰¹å¾...\n",
      "åŸºç¡€ç‰¹å¾æ•°é‡ (åŒ…æ‹¬ Diff å’Œ Accel): 32\n",
      "æ€»ç‰¹å¾æ•°: 64 (å…¨é¢‘ç‡æ¢³ + é€Ÿåº¦ + åŠ é€Ÿåº¦)\n",
      "åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\n",
      "æ•°æ®: è®­ç»ƒ51378, æµ‹è¯•8521\n",
      "è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\n",
      "\n",
      "LGBM æœ€ä½³ CV RÂ² (M_CV_R2): 0.0536\n",
      "LGBM æ£€éªŒé›† Test RÂ² (M_T_R2): 0.0352\n",
      "âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\n",
      "æœ€ä½³å‚æ•°: OrderedDict({'colsample_bytree': 0.7, 'learning_rate': 0.006969831419601297, 'n_estimators': 423, 'num_leaves': 5, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'subsample': 0.7})\n",
      "\n",
      "ç‰¹å¾é‡è¦æ€§ (Top 20):\n",
      "Mod_Hale_22y_sin              461\n",
      "Mod_Hale_22y_cos              274\n",
      "Planetary_Scaled_Diff         201\n",
      "Hale_22y_cos                  155\n",
      "Mod_Planetary_Scaled_Diff     149\n",
      "Mod_QBO_2.7y_cos              115\n",
      "Mod_B0_sq                      75\n",
      "Mod_QBO_2.7y_sin               37\n",
      "Mod_QBO_2.2y_cos               37\n",
      "Mod_Annual_360d_sin            29\n",
      "Mod_QBO_1.7y_cos               28\n",
      "Mod_Annual_370d_cos            24\n",
      "Mod_Annual_370d_sin            20\n",
      "Mod_QBO_2.2y_sin               20\n",
      "Mod_Planetary_Scaled_Accel     15\n",
      "Mod_Annual_365d_sin            10\n",
      "Mod_B0                          8\n",
      "Hale_22y_sin                    7\n",
      "Mod_Annual_365d_cos             6\n",
      "QBO_1.7y_sin                    5\n",
      "\n",
      "Top 20 ä¸­ï¼Œæœ‰ 16 ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\n",
      "\n",
      "ä¿å­˜æ¨¡å‹åŠ Scalers...\n",
      "æ¨¡å‹å·²ä¿å­˜: LGBM_Models/M0+2_best_lgbm.joblib\n",
      "ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\n",
      "\n",
      "============================================================\n",
      "ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„äºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ.csv\n",
      "ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« 73780 è¡Œæ•°æ®ã€‚\n",
      "\n",
      "============================================================\n",
      "LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ æ€»ç»“\n",
      "============================================================\n",
      "model  M_CV_R2  M_T_R2  n_features  top_20_mod  time(s)\n",
      " M8+2   0.0629  0.0108          64          15 516.4267\n",
      " M8+3   0.0301  0.1216          64          17 401.2693\n",
      " M0+3   0.0381  0.0968          64          15 358.3492\n",
      " M0+2   0.0536  0.0352          64          16 400.0175\n",
      "\n",
      "å¹³å‡ Test RÂ² (M_T_R2): 0.0661\n",
      "âœ…âœ…âœ… å·¨å¤§æˆåŠŸ: æ‰€æœ‰æ¨¡å‹ Test RÂ² å‡ä¸ºæ­£å€¼ï¼\n",
      "ğŸ’¡ æ´å¯Ÿ: è°ƒåˆ¶ç‰¹å¾ (Mod_) åœ¨æ¨¡å‹ä¸­å æœ‰é‡è¦åœ°ä½ã€‚\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import os  # æ–°å¢ï¼šç”¨äºåˆ›å»ºç›®å½•\n",
    "import joblib  # æ–°å¢ï¼šç”¨äºä¿å­˜æ¨¡å‹\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "# å¯¼å…¥ QuantileTransformer (å…³é”®ä¿®å¤)\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# --- æ ¸å¿ƒï¼šéçº¿æ€§æ¨¡å‹å¯¼å…¥ ---\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    print(\"LightGBM å¯¼å…¥æˆåŠŸã€‚\")\n",
    "except ImportError:\n",
    "    print(\"é”™è¯¯ï¼šæœªæ‰¾åˆ° lightgbm åº“ã€‚\")\n",
    "    print(\"è¯·å®‰è£…: pip install lightgbm\")\n",
    "    exit()\n",
    "\n",
    "# å¤©æ–‡å­¦åº“å¯¼å…¥\n",
    "try:\n",
    "    from astropy.time import Time\n",
    "    import astropy.units as u\n",
    "    from sunpy.coordinates import sun\n",
    "except ImportError:\n",
    "    print(\"ç¼ºå°‘å¤©æ–‡å­¦åº“\")\n",
    "    exit()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def run_lgbm_full_comb_validation(\n",
    "    data_full, model_name, train_start_date, train_end_date, test_end_date\n",
    "):\n",
    "    \"\"\"\n",
    "    è¿è¡Œ LGBM (æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ)\n",
    "    - ç‰¹å¾: B0 + æ‰€æœ‰è‘—åå‘¨æœŸ (22y, QBO, 1y, 154d, 25-30d)\n",
    "    - è°ƒåˆ¶: 11å¹´è¡Œæ˜Ÿæ‹Ÿåˆ\n",
    "    - Yå˜æ¢: QuantileTransformer\n",
    "    - è°ƒä¼˜: å¼ºæ­£åˆ™åŒ–\n",
    "    - æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸé¢„æµ‹\n",
    "    \"\"\"\n",
    "    \n",
    "    # ä½¿ç”¨ä¼ å…¥çš„å®Œæ•´æ•°æ®\n",
    "    data = data_full.copy() \n",
    "    \n",
    "    target_residual_column = f'æ®‹å·®_{model_name}'\n",
    "    planetary_fit_column = f'æ‹ŸåˆSSN_{model_name}'\n",
    "    \n",
    "    # ç¡®ä¿æ¨¡å‹ä¿å­˜ç›®å½•å­˜åœ¨\n",
    "    os.makedirs(\"LGBM_Models\", exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n=== LGBM æœ€ç»ˆå…¨é¢‘ç‡æ¢³ç‰ˆ: {model_name} ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨\n",
    "    if target_residual_column not in data.columns or planetary_fit_column not in data.columns:\n",
    "        print(f\"é”™è¯¯: ç¼ºå°‘åˆ— {target_residual_column} æˆ– {planetary_fit_column}\")\n",
    "        return None, None\n",
    "\n",
    "    # --- 1. ç‰¹å¾å·¥ç¨‹ï¼šB0 + å…¨é¢‘ç‡æ¢³ (åœ¨æ‰€æœ‰æ—¥æœŸä¸Š) ---\n",
    "    print(\"1. ç”Ÿæˆ B0 æ˜Ÿå†ç‰¹å¾ + å…¨é¢‘ç‡æ¢³ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    times_astropy = Time(data['æ—¥æœŸ'].values)\n",
    "    \n",
    "    original_feature_names = []\n",
    "    \n",
    "    # B0 (æ—¥é¢ä¸­å¿ƒçº¬åº¦) - çœŸå®å¹´åº¦æŒ¯å¹…\n",
    "    b0_deg = sun.B0(times_astropy).deg\n",
    "    data['B0'] = b0_deg\n",
    "    data['B0_sq'] = b0_deg ** 2\n",
    "    original_feature_names.extend(['B0', 'B0_sq'])\n",
    "    \n",
    "    # åŸºäºæ—¶é—´çš„å›ºå®šé¢‘ç‡ç‰¹å¾\n",
    "    days_since_start = (data['æ—¥æœŸ'] - data['æ—¥æœŸ'].min()).dt.days\n",
    "    \n",
    "    # === å®šä¹‰æˆ‘ä»¬çš„é¢‘ç‡æ¢³ ===\n",
    "    \n",
    "    # 1. Hale (22y)\n",
    "    hale_rad = 2 * np.pi * days_since_start / (22.0 * 365.25)\n",
    "    data['Hale_22y_sin'] = np.sin(hale_rad)\n",
    "    data['Hale_22y_cos'] = np.cos(hale_rad)\n",
    "    original_feature_names.extend(['Hale_22y_sin', 'Hale_22y_cos'])\n",
    "\n",
    "    # 2. QBO (1.5y - 3y)\n",
    "    qbo_periods = [1.7, 2.2, 2.7] # å¹´\n",
    "    for p in qbo_periods:\n",
    "        rad = 2 * np.pi * days_since_start / (p * 365.25)\n",
    "        name = f'QBO_{p:.1f}y'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 3. Annual (1y)\n",
    "    annual_periods = [360, 365.25, 370] # å¤©\n",
    "    for p in annual_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Annual_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "\n",
    "    # 4. Rieger (154d)\n",
    "    rieger_rad = 2 * np.pi * days_since_start / 154\n",
    "    data['Rieger_154d_sin'] = np.sin(rieger_rad)\n",
    "    data['Rieger_154d_cos'] = np.cos(rieger_rad)\n",
    "    original_feature_names.extend(['Rieger_154d_sin', 'Rieger_154d_cos'])\n",
    "\n",
    "    # 5. Rotation (25d-30d)\n",
    "    rotation_periods = [25, 26, 27, 28, 29, 30] # å¤©\n",
    "    for p in rotation_periods:\n",
    "        rad = 2 * np.pi * days_since_start / p\n",
    "        name = f'Rotation_{p:.0f}d'\n",
    "        data[f'{name}_sin'] = np.sin(rad)\n",
    "        data[f'{name}_cos'] = np.cos(rad)\n",
    "        original_feature_names.extend([f'{name}_sin', f'{name}_cos'])\n",
    "    \n",
    "    \n",
    "    # --- 2. è°ƒåˆ¶ç‰¹å¾å·¥ç¨‹ (é‡æ„) ---\n",
    "    # ç›®æ ‡ï¼šåœ¨è®­ç»ƒé›†ä¸Š fit Scalerï¼Œåœ¨å…¨å‘¨æœŸä¸Š transform\n",
    "    print(\"2. ç”Ÿæˆè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)...\")\n",
    "    \n",
    "    # a. åˆ›å»ºç”¨äºæ‹Ÿåˆ Scaler çš„è®­ç»ƒæ©ç \n",
    "    # è®­ç»ƒé›†æ©ç ï¼ˆä»…ç”¨äºæ‹Ÿåˆ Scaler å’Œæ¨¡å‹ï¼‰\n",
    "    train_mask_dates = (data['æ—¥æœŸ'] >= train_start_date) & (data['æ—¥æœŸ'] <= train_end_date)\n",
    "    # å¿…é¡»æ˜¯å¹²å‡€çš„ã€éNaNçš„æ•°æ®\n",
    "    train_mask_clean = train_mask_dates & data[target_residual_column].notna() & data[planetary_fit_column].notna()\n",
    "    \n",
    "    if train_mask_clean.sum() == 0:\n",
    "        print(f\"é”™è¯¯ï¼šåœ¨ {train_start_date} å’Œ {train_end_date} ä¹‹é—´æ²¡æœ‰å¹²å‡€çš„è®­ç»ƒæ•°æ®ã€‚\")\n",
    "        return None, None\n",
    "        \n",
    "    # b. Fit è°ƒåˆ¶å™¨ (11å¹´å‘¨æœŸä¿¡å·) Scaler (ä»…åœ¨è®­ç»ƒæ•°æ®ä¸Š)\n",
    "    planetary_fit_values_train = data.loc[train_mask_clean, [planetary_fit_column]]\n",
    "    scaler_fit = StandardScaler()\n",
    "    scaler_fit.fit(planetary_fit_values_train)\n",
    "    \n",
    "    # c. Transform (å…¨å‘¨æœŸ)\n",
    "    # è­¦å‘Šï¼šå¦‚æœ planetary_fit_column åœ¨æœªæ¥æ˜¯ NaNï¼Œè¿™é‡Œä¼šäº§ç”Ÿ NaN\n",
    "    planetary_fit_values_full = data[[planetary_fit_column]].fillna(0) # å‡è®¾æœªæ¥æ‹Ÿåˆä¸º0ï¼ˆå¦‚æœä¸¢å¤±ï¼‰ï¼Œè¿™ä¸ç†æƒ³ä½†èƒ½é˜²æ­¢å´©æºƒ\n",
    "    data['Planetary_Scaled'] = scaler_fit.transform(planetary_fit_values_full).flatten()\n",
    "\n",
    "    # --- [ *** æ­¤å¤„ä¿®æ”¹ *** ] ---\n",
    "    \n",
    "    # 2.c.1: åˆ›å»ºå˜åŒ–ç‡ç‰¹å¾ (é€Ÿåº¦)\n",
    "    print(\"... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Diff' (é€Ÿåº¦) ç‰¹å¾...\")\n",
    "    data['Planetary_Scaled_Diff'] = data['Planetary_Scaled'].diff(1).fillna(0)\n",
    "    \n",
    "    # 2.c.2: åˆ›å»ºåŠ é€Ÿåº¦ç‰¹å¾ (é€Ÿåº¦çš„å˜åŒ–ç‡)\n",
    "    print(\"... æ­£åœ¨æ·»åŠ  'Planetary_Scaled_Accel' (åŠ é€Ÿåº¦) ç‰¹å¾...\")\n",
    "    data['Planetary_Scaled_Accel'] = data['Planetary_Scaled_Diff'].diff(1).fillna(0)\n",
    "\n",
    "    # 2.c.3: å°†å®ƒä»¬éƒ½æ·»åŠ åˆ° *åŸºç¡€* ç‰¹å¾åˆ—è¡¨\n",
    "    # å…³é”®ï¼šè¿™æ ·å®ƒä»¬åœ¨ä¸‹ä¸€æ­¥ä¸­ä¼šè‡ªåŠ¨è·å¾—è‡ªå·±çš„ \"Mod_\" ç‰ˆæœ¬\n",
    "    original_feature_names.append('Planetary_Scaled_Diff')\n",
    "    original_feature_names.append('Planetary_Scaled_Accel')\n",
    "    # --- [ *** ä¿®æ”¹ç»“æŸ *** ] ---\n",
    "    \n",
    "    # d. åˆ›å»ºè°ƒåˆ¶ç‰¹å¾ (å…¨å‘¨æœŸ)\n",
    "    modulation_feature_names = []\n",
    "    for feature in original_feature_names:\n",
    "        new_feature_name = f'Mod_{feature}'\n",
    "        data.loc[:, new_feature_name] = data['Planetary_Scaled'] * data[feature]\n",
    "        modulation_feature_names.append(new_feature_name)\n",
    "    \n",
    "    feature_names = original_feature_names + modulation_feature_names\n",
    "\n",
    "    # æ‰“å°è¯­å¥ç°åœ¨ä¼šæ˜¾ç¤º 32 ä¸ªåŸºç¡€ç‰¹å¾ (30ä¸ªåŸå§‹ + 1ä¸ªDiff + 1ä¸ªAccel)\n",
    "    print(f\"åŸºç¡€ç‰¹å¾æ•°é‡ (åŒ…æ‹¬ Diff å’Œ Accel): {len(original_feature_names)}\") \n",
    "    # ä½ çš„æ€»ç‰¹å¾æ•°ç°åœ¨åº”è¯¥æ˜¯ 64 (32 + 32)\n",
    "    print(f\"æ€»ç‰¹å¾æ•°: {len(feature_names)} (å…¨é¢‘ç‡æ¢³ + é€Ÿåº¦ + åŠ é€Ÿåº¦)\")\n",
    "    \n",
    "    # --- 3. æ•°æ®åˆ†å‰²ä¸å˜æ¢ (ç”¨äºè®­ç»ƒ) ---\n",
    "    \n",
    "    # ä»…ä½¿ç”¨å…·æœ‰æœ‰æ•ˆæ®‹å·®çš„è¡Œè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•\n",
    "    data_clean = data.dropna(subset=[target_residual_column] + feature_names)\n",
    "    \n",
    "    X = data_clean[feature_names]\n",
    "    Y_raw = data_clean[target_residual_column] # Y åŸå§‹å€¼\n",
    "    groups = data_clean['æ—¥æœŸ'].dt.year\n",
    "    dates = data_clean['æ—¥æœŸ']\n",
    "    \n",
    "    train_mask = (dates >= train_start_date) & (dates <= train_end_date)\n",
    "    test_start_date_dt = pd.to_datetime(train_end_date) + pd.Timedelta(days=1)\n",
    "    test_mask = (dates >= test_start_date_dt) & (dates <= test_end_date)\n",
    "    \n",
    "    X_train_raw = X[train_mask]\n",
    "    Y_train_raw = Y_raw[train_mask]\n",
    "    X_test_raw = X[test_mask]\n",
    "    Y_test_raw = Y_raw[test_mask]\n",
    "    groups_train = groups[train_mask]\n",
    "    \n",
    "    if len(X_train_raw) == 0 or len(X_test_raw) == 0:\n",
    "        print(\"é”™è¯¯ï¼šè®­ç»ƒé›†æˆ–æµ‹è¯•é›†ä¸ºç©º\")\n",
    "        return None, None\n",
    "\n",
    "    # a. Fit X å˜æ¢ (StandardScaler)\n",
    "    feature_scaler = StandardScaler()\n",
    "    X_train = feature_scaler.fit_transform(X_train_raw)\n",
    "    X_test = feature_scaler.transform(X_test_raw)\n",
    "\n",
    "    # b. Fit Y å˜æ¢ (QuantileTransformer) - å…³é”®ä¿®å¤\n",
    "    print(\"åº”ç”¨ QuantileTransformer ç¨³å®šç›®æ ‡å˜é‡ Y (æ®‹å·®)...\")\n",
    "    target_transformer = QuantileTransformer(output_distribution='normal', random_state=42)\n",
    "    Y_train = target_transformer.fit_transform(Y_train_raw.values.reshape(-1, 1)).flatten()\n",
    "    Y_test = target_transformer.transform(Y_test_raw.values.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    print(f\"æ•°æ®: è®­ç»ƒ{len(X_train)}, æµ‹è¯•{len(X_test)}\")\n",
    "    \n",
    "    # --- 4. è´å¶æ–¯ä¼˜åŒ– - LGBM (å¼ºæ­£åˆ™åŒ–) ---\n",
    "    n_splits = max(2, min(5, groups_train.nunique()))\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    \n",
    "    search_spaces = {\n",
    "        'n_estimators': Integer(100, 800),\n",
    "        'num_leaves': Integer(5, 30),\n",
    "        'learning_rate': Real(1e-3, 0.1, 'log-uniform'),\n",
    "        'reg_alpha': Real(0.1, 20.0, 'log-uniform'), \n",
    "        'reg_lambda': Real(0.1, 20.0, 'log-uniform'),\n",
    "        'subsample': Real(0.7, 1.0, 'uniform'),\n",
    "        'colsample_bytree': Real(0.7, 1.0, 'uniform')\n",
    "    }\n",
    "    \n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        random_state=42, \n",
    "        n_jobs=1, \n",
    "        objective='regression_l1',\n",
    "        force_row_wise=True, # å¼ºåˆ¶ä½¿ç”¨è¡Œä¼˜å…ˆï¼Œæ¶ˆé™¤è‡ªåŠ¨æ£€æµ‹çš„æç¤º\n",
    "        verbose=-1           # æŠ‘åˆ¶æ‰€æœ‰ LightGBM çš„å†…éƒ¨è¾“å‡ºï¼ˆæ¨èï¼‰\n",
    "    )\n",
    "\n",
    "    opt_lgbm = BayesSearchCV(\n",
    "        lgb_model, \n",
    "        search_spaces, \n",
    "        n_iter=100, \n",
    "        cv=gkf, \n",
    "        n_jobs=-1,\n",
    "        random_state=42, \n",
    "        scoring='r2'\n",
    "    )\n",
    "    \n",
    "    print(\"è®­ç»ƒLGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ)...\")\n",
    "    opt_lgbm.fit(X_train, Y_train, groups=groups_train)\n",
    "    \n",
    "    # --- 5. ç»“æœåˆ†æ ---\n",
    "    best_model = opt_lgbm.best_estimator_\n",
    "    \n",
    "    # é¢„æµ‹æ£€éªŒé›†ç»“æœ\n",
    "    Y_pred_test = best_model.predict(X_test)\n",
    "    \n",
    "    # è®¡ç®— M_T_R2 (åœ¨å˜æ¢åçš„Yä¸Š)\n",
    "    final_r2_test = r2_score(Y_test, Y_pred_test) \n",
    "    \n",
    "    # è·å– M_CV_R2 (åœ¨å˜æ¢åçš„Yä¸Š)\n",
    "    best_cv_score = opt_lgbm.best_score_\n",
    "    \n",
    "    print(f\"\\nLGBM æœ€ä½³ CV RÂ² (M_CV_R2): {best_cv_score:.4f}\")\n",
    "    print(f\"LGBM æ£€éªŒé›† Test RÂ² (M_T_R2): {final_r2_test:.4f}\")\n",
    "    \n",
    "    if final_r2_test > 0: # ä½¿ç”¨ä¿®æ­£åçš„å˜é‡åè¿›è¡Œæ£€æŸ¥\n",
    "        print(\"âœ… æˆåŠŸï¼æ¨¡å‹RÂ²ä¸ºæ­£å€¼ã€‚\")\n",
    "    else:\n",
    "        print(\"âŒ RÂ²ä»ä¸ºè´Ÿå€¼ã€‚\")\n",
    "        \n",
    "    print(f\"æœ€ä½³å‚æ•°: {opt_lgbm.best_params_}\")\n",
    "    \n",
    "    # ç‰¹å¾é‡è¦æ€§\n",
    "    importances = pd.Series(best_model.feature_importances_, index=feature_names)\n",
    "    print(\"\\nç‰¹å¾é‡è¦æ€§ (Top 20):\")\n",
    "    top_features = importances.sort_values(ascending=False).head(20)    \n",
    "    print(top_features.to_string())\n",
    "    \n",
    "    mod_features_in_top = [f for f in top_features.index if f.startswith('Mod_')]\n",
    "    print(f\"\\nTop 20 ä¸­ï¼Œæœ‰ {len(mod_features_in_top)} ä¸ªæ˜¯è°ƒåˆ¶ç‰¹å¾ã€‚\")\n",
    "    \n",
    "    # --- 6. æ–°å¢åŠŸèƒ½ï¼šä¿å­˜æ¨¡å‹ ---\n",
    "    print(\"\\nä¿å­˜æ¨¡å‹åŠ Scalers...\")\n",
    "    model_path = f\"LGBM_Models/{model_name}_best_lgbm.joblib\"\n",
    "    fscaler_path = f\"LGBM_Models/{model_name}_feature_scaler.joblib\"\n",
    "    tscaler_path = f\"LGBM_Models/{model_name}_target_transformer.joblib\"\n",
    "    \n",
    "    joblib.dump(best_model, model_path)\n",
    "    joblib.dump(feature_scaler, fscaler_path)\n",
    "    joblib.dump(target_transformer, tscaler_path)\n",
    "    print(f\"æ¨¡å‹å·²ä¿å­˜: {model_path}\")\n",
    "\n",
    "    # --- 7. æ–°å¢åŠŸèƒ½ï¼šç”Ÿæˆå…¨å‘¨æœŸé¢„æµ‹ ---\n",
    "    print(\"ç”Ÿæˆå…¨å‘¨æœŸï¼ˆè‡³2050å¹´ï¼‰é¢„æµ‹...\")\n",
    "    \n",
    "    # å‡†å¤‡å…¨å‘¨æœŸçš„ X ç‰¹å¾\n",
    "    # å¿…é¡»å¡«å……ç‰¹å¾ä¸­çš„NaNï¼ˆä¾‹å¦‚ï¼Œå¦‚æœ Planetary_Scaled æœ€ç»ˆä¸ºNaNï¼‰\n",
    "    X_full = data[feature_names].fillna(0)    \n",
    "    \n",
    "    X_full_scaled = feature_scaler.transform(X_full)\n",
    "    Y_pred_full_transformed = best_model.predict(X_full_scaled)\n",
    "    \n",
    "    # åå˜æ¢å›åŸå§‹å°ºåº¦\n",
    "    Y_pred_full_raw = target_transformer.inverse_transform(Y_pred_full_transformed.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    # åˆ›å»ºé¢„æµ‹åˆ—å’ŒäºŒæ¬¡æ®‹å·®åˆ—\n",
    "    pred_col_name = f'LGBM_Pred_{model_name}'\n",
    "    resid_col_name = f'LGBM_Resid_{model_name}'\n",
    "    \n",
    "    data[pred_col_name] = Y_pred_full_raw\n",
    "    # åŸå§‹æ®‹å·® - LGBMé¢„æµ‹çš„æ®‹å·® = äºŒæ¬¡æ®‹å·®\n",
    "    data[resid_col_name] = data[target_residual_column] - data[pred_col_name]\n",
    "    \n",
    "    # å‡†å¤‡ç»Ÿè®¡å­—å…¸\n",
    "    stats_dict = {\n",
    "        'model': model_name,\n",
    "        # æ–°å¢ M_CV_R2 å’Œ M_T_R2\n",
    "        'M_T_R2': final_r2_test,\n",
    "        'M_CV_R2': best_cv_score,\n",
    "        'n_features': len(feature_names),\n",
    "        'top_20_mod_count': len(mod_features_in_top),\n",
    "        'best_params': opt_lgbm.best_params_,\n",
    "        'training_time': time.time() - start_time\n",
    "    }\n",
    "\n",
    "    # è¿”å›åŒ…å«æ–°åˆ—çš„DataFrameï¼ˆä»…å«å¿…è¦åˆ—ï¼‰å’Œç»Ÿè®¡ç»“æœ\n",
    "    return data[['æ—¥æœŸ', pred_col_name, resid_col_name]], stats_dict\n",
    "\n",
    "\n",
    "# ä¸»æ‰§è¡Œ - è¿è¡Œ LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ\n",
    "if __name__ == \"__main__\":\n",
    "    model_splits = {\n",
    "        'M8+2': '1996-08-01', \n",
    "        'M8+3': '1986-08-01',\n",
    "        'M0+3': '1986-09-01', \n",
    "        'M0+2': '1996-08-01'\n",
    "    }\n",
    "    \n",
    "    print(\"=== è¿è¡Œ LGBM (å…¨é¢‘ç‡æ¢³ç‰ˆ: B0 + 22y, QBO, 1y, 154d, 25-30d) ===\")\n",
    "    print(\"ç­–ç•¥: ç‰©ç†å…¨é¢‘ç‡æ¢³ + 11å¹´è°ƒåˆ¶ + ç›®æ ‡ç¨³å®š + å¼ºæ­£åˆ™åŒ–\")\n",
    "    print(\"æ–°å¢: ä¿å­˜æ¨¡å‹å’Œå…¨å‘¨æœŸäºŒæ¬¡æ®‹å·®\")\n",
    "    \n",
    "    # --- æ–°å¢ï¼šåœ¨å¾ªç¯å¤–åŠ è½½å’Œå‡†å¤‡æ•°æ® ---\n",
    "    try:\n",
    "        data_source_file = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ1ç»“æœ.csv\"\n",
    "        print(f\"\\nåŠ è½½æºæ•°æ®: {data_source_file}\")\n",
    "        full_data_to_save = pd.read_csv(data_source_file, parse_dates=['æ—¥æœŸ'])\n",
    "    except Exception as e:\n",
    "        print(f\"è‡´å‘½é”™è¯¯ï¼šæ— æ³•è¯»å– {data_source_file}ã€‚é”™è¯¯: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # æ£€æŸ¥å¹¶æ‰©å±•æ—¥æœŸè‡³2050å¹´\n",
    "    max_date_in_file = full_data_to_save['æ—¥æœŸ'].max()\n",
    "    target_date = pd.to_datetime('2050-12-31')\n",
    "    \n",
    "    if max_date_in_file < target_date:\n",
    "        print(f\"è­¦å‘Š: æºæ•°æ®æœ€å¤§æ—¥æœŸä¸º {max_date_in_file}ã€‚\")\n",
    "        print(f\"è­¦å‘Š: æ­£åœ¨æ‰©å±•æ—¥æœŸèŒƒå›´è‡³ {target_date}ã€‚\")\n",
    "        print(\"è­¦å‘Š: è¯·ç¡®ä¿ 'æ‹ŸåˆSSN' (è¡Œæ˜Ÿæ‹Ÿåˆ) åˆ—åœ¨æºæ–‡ä»¶ä¸­å·²å¤–æ¨è‡³2050å¹´ï¼Œå¦åˆ™é¢„æµ‹å°†ä¸å‡†ç¡®ï¼\")\n",
    "        \n",
    "        all_dates_df = pd.DataFrame({'æ—¥æœŸ': pd.date_range(\n",
    "            start=full_data_to_save['æ—¥æœŸ'].min(), \n",
    "            end=target_date, \n",
    "            freq='D'\n",
    "        )})\n",
    "        full_data_to_save = pd.merge(all_dates_df, full_data_to_save, on='æ—¥æœŸ', how='left')\n",
    "\n",
    "    # ç”¨äºä¿å­˜ç»Ÿè®¡ç»“æœ\n",
    "    results_stats_list = []\n",
    "    \n",
    "    # å¾ªç¯å¤„ç†æ¯ä¸ªæ¨¡å‹\n",
    "    for model_name, split_date in model_splits.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"å¤„ç†æ¨¡å‹: {model_name} (è®­ç»ƒç»“æŸäº {split_date})\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # ä¼ å…¥å®Œæ•´æ•°æ®\n",
    "        result_df, stats_dict = run_lgbm_full_comb_validation(\n",
    "            data_full=full_data_to_save.copy(), # ä¼ å…¥æ•°æ®çš„å‰¯æœ¬\n",
    "            model_name=model_name,\n",
    "            train_start_date='1855-12-02',\n",
    "            train_end_date=split_date,\n",
    "            test_end_date='2019-11-30'\n",
    "        )\n",
    "        \n",
    "        if result_df is not None and stats_dict is not None:\n",
    "            results_stats_list.append(stats_dict)\n",
    "            # å°†è¯¥æ¨¡å‹çš„ç»“æœåˆå¹¶å›ä¸»DataFrame\n",
    "            full_data_to_save = pd.merge(full_data_to_save, result_df, on='æ—¥æœŸ', how='left')\n",
    "    \n",
    "    # --- æ–°å¢ï¼šä¿å­˜åŒ…å«æ‰€æœ‰ç»“æœçš„CSV ---\n",
    "    if results_stats_list:\n",
    "        output_filename = \"ç»¼åˆåˆ†æç»“æœ/æ±‡æ€»æ‹Ÿåˆ2_LGBMç»“æœ.csv\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ä¿å­˜æ‰€æœ‰æ¨¡å‹çš„äºŒæ¬¡æ‹Ÿåˆå’Œæ®‹å·®åˆ°: {output_filename}\")\n",
    "        try:\n",
    "            full_data_to_save.to_csv(output_filename, index=False, float_format='%.6f')\n",
    "            print(f\"ä¿å­˜æˆåŠŸã€‚æ–‡ä»¶åŒ…å« {len(full_data_to_save)} è¡Œæ•°æ®ã€‚\")\n",
    "        except Exception as e:\n",
    "            print(f\"ä¿å­˜CSVå¤±è´¥: {e}\")\n",
    "        \n",
    "        # --- æ‰“å°æ€»ç»“æŠ¥å‘Š (ä½¿ç”¨ç»Ÿè®¡æ•°æ®) ---\n",
    "        results_to_print = []\n",
    "        for r in results_stats_list:\n",
    "            results_to_print.append({\n",
    "                'model': r['model'],\n",
    "                # ä¿®æ­£: ä½¿ç”¨æ–°çš„é”®å M_T_R2\n",
    "                'M_T_R2': r['M_T_R2'], \n",
    "                # ä¿®æ­£: åŠ å…¥ M_CV_R2 æ–¹ä¾¿æŸ¥çœ‹\n",
    "                'M_CV_R2': r['M_CV_R2'], \n",
    "                'n_features': r['n_features'],\n",
    "                'top_20_mod': r['top_20_mod_count'],\n",
    "                'time(s)': r['training_time']\n",
    "            })\n",
    "            \n",
    "        results_df = pd.DataFrame(results_to_print)\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"LGBM å…¨é¢‘ç‡æ¢³ç‰ˆ æ€»ç»“\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # æ‰“å°å…³é”®åˆ—\n",
    "        print(results_df[['model', 'M_CV_R2', 'M_T_R2', 'n_features', 'top_20_mod', 'time(s)']].to_string(index=False, float_format=\"%.4f\"))\n",
    "        \n",
    "        # ä½¿ç”¨ M_T_R2 è®¡ç®—å¹³å‡å€¼\n",
    "        avg_r2 = results_df['M_T_R2'].mean()\n",
    "        print(f\"\\nå¹³å‡ Test RÂ² (M_T_R2): {avg_r2:.4f}\")\n",
    "        \n",
    "        # ä½¿ç”¨ M_T_R2 æ£€æŸ¥æ­£è´Ÿå€¼\n",
    "        positive_r2 = results_df[results_df['M_T_R2'] > 0]\n",
    "        if len(positive_r2) == len(results_df):\n",
    "            print(\"âœ…âœ…âœ… å·¨å¤§æˆåŠŸ: æ‰€æœ‰æ¨¡å‹ Test RÂ² å‡ä¸ºæ­£å€¼ï¼\")\n",
    "        elif len(positive_r2) > 0:\n",
    "            print(f\"âœ… æˆåŠŸ: {len(positive_r2)} ä¸ªæ¨¡å‹è·å¾—æ­£ Test RÂ²ã€‚\")\n",
    "        else:\n",
    "            print(\"âŒ å¤±è´¥: æ‰€æœ‰æ¨¡å‹ Test RÂ² ä»ä¸ºè´Ÿå€¼ã€‚\")\n",
    "        \n",
    "        if results_df['top_20_mod'].mean() >= 10:    \n",
    "             print(\"ğŸ’¡ æ´å¯Ÿ: è°ƒåˆ¶ç‰¹å¾ (Mod_) åœ¨æ¨¡å‹ä¸­å æœ‰é‡è¦åœ°ä½ã€‚\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\næ‰€æœ‰æ¨¡å‹å¤„ç†å¤±è´¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1ac3f-ad5e-45a2-b9eb-61fb2dd8b0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
